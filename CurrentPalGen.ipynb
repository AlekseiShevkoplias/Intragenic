{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CurrentPalGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlekseiShevkoplias/Intragenic/blob/rubbish/CurrentPalGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km42r3SmeE_p"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate, Lambda, Add, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igrWDv1c2ano"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM, Input\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "COMPLEMENT = {\n",
        "    'A': 'T',\n",
        "    'G': 'C',\n",
        "    'T': 'A', \n",
        "    'C': 'G'\n",
        "}\n",
        "\n",
        "NUC = ['A', 'T', 'G', 'C']\n",
        "\n",
        "TOKENS = {\n",
        "    'A': [1, 0, 0, 0],\n",
        "    'G': [0, 1, 0, 0],\n",
        "    'T': [0, 0, 1, 0], \n",
        "    'C': [0, 0, 0, 1], \n",
        "    'X': [0, 0, 0, 0]\n",
        "}\n",
        "\n",
        "def tokenize(seq):\n",
        "    tokenized = []\n",
        "    for nuc in seq:\n",
        "        tokenized.append(TOKENS[nuc])\n",
        "    return tokenized\n",
        "\n",
        "def generate_palindromes(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA palindromes.\n",
        "    n: the number of palindromes to be generated\n",
        "    \"\"\"\n",
        "    palindromes = []\n",
        "    for j in range(n):\n",
        "  \n",
        "        pal_length = random.randint(2, 10)\n",
        "\n",
        "        palindrome = ''\n",
        "        for i in range(50 - pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "        for i in range(pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "        for i in range(pal_length - 1, -1, -1):\n",
        "            palindrome += COMPLEMENT[palindrome[i]]\n",
        "        \n",
        "        for i in range(50 - pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "\n",
        "        palindromes.append(palindrome)\n",
        "\n",
        "    return palindromes\n",
        "\n",
        "\n",
        "def generate_sd(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA with inserted SD.\n",
        "    n: the number of palindromes to be generated.\n",
        "    \"\"\"\n",
        "    sds = []\n",
        "    for i in range(n):\n",
        "        sd = ''\n",
        "        for i in range(47):\n",
        "            sd += random.choice(NUC)\n",
        "        sd += 'AGGAGG'\n",
        "        for i in range(47):\n",
        "            sd += random.choice(NUC)\n",
        "\n",
        "        sds.append(sd)\n",
        "\n",
        "    return sds\n",
        "\n",
        "def test_sd(seq):\n",
        "    if 'AGGAGG' in seq[47:54]:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def test_palindrome(seq):\n",
        "    \"\"\"\n",
        "    Tests whether the seq is a DNA palindrome or not.\n",
        "    seq: A str object with the DNA sequence\n",
        "    return: True if seq is a palindrome and False if not\n",
        "    \"\"\"\n",
        "    assert isinstance(seq, str)\n",
        "    complementary = ''\n",
        "    for i in range(len(seq)//2 - 1, -1, -1):\n",
        "        complementary += COMPLEMENT[seq[i]]\n",
        "    return complementary == seq[len(seq)//2:]\n",
        "\n",
        "def generate_negatives(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA non-palindromes.\n",
        "    n: the number of negatives to be generated\n",
        "    \"\"\"\n",
        "    negs = []\n",
        "    for j in range(n):\n",
        "        is_palindrome = True\n",
        "        neg_length = random.randint(2, 10) * 2\n",
        "        preneg = ''\n",
        "\n",
        "        for i in range(50 - neg_length//2):\n",
        "            preneg += random.choice(NUC)\n",
        "\n",
        "        while is_palindrome:\n",
        "            \n",
        "\n",
        "            neg = ''\n",
        "\n",
        "            for i in range(neg_length):\n",
        "                neg += random.choice(NUC)\n",
        "\n",
        "            is_palindrome = test_palindrome(neg) or test_sd(neg)\n",
        "        neg = preneg + neg\n",
        "\n",
        "        for i in range(50 - neg_length//2):\n",
        "            neg += random.choice(NUC)\n",
        "\n",
        "        negs.append(neg)\n",
        "\n",
        "    return negs\n",
        "\n",
        "def generate_rubbish(n):\n",
        "    \"\"\"\n",
        "    Negative with X in the middle\n",
        "    \"\"\"\n",
        "    rubbishes = []\n",
        "    for i in range(n):\n",
        "        rubbish = ''\n",
        "        for i in range(50):\n",
        "            rubbish += random.choice(NUC)\n",
        "        rubbish += 'X'\n",
        "        for i in range(49):\n",
        "            rubbish += random.choice(NUC)\n",
        "        rubbishes.append(rubbish)\n",
        "\n",
        "    return rubbishes\n",
        "\n",
        "class PalNegDataset:\n",
        "    def __init__(self, n_pal, n_sd, n_neg, n_rubbish = 0):\n",
        "        \n",
        "        self.n_pal = n_pal\n",
        "        self.n_sd = n_sd\n",
        "        self.n_neg = n_neg\n",
        "        self.n_rubbish = n_rubbish\n",
        "\n",
        "        self.palindromes = generate_palindromes(n_pal)\n",
        "        self.sds = generate_sd(n_sd)\n",
        "        self.negatives = generate_negatives(n_neg)\n",
        "        self.data = self.generate_data()\n",
        "        self.sequences = self.palindromes + self.sds + self.negatives\n",
        "\n",
        "        random.shuffle(self.sequences)\n",
        "        self.status = K.constant([self.data[key] for key in self.sequences])\n",
        "        self.tokenized_seq = np.array([tokenize(seq) for seq in self.sequences])\n",
        "        self.middles = np.array([tokenize(seq[50]) for seq in self.sequences])\n",
        "\n",
        "        # different stuff (likely will be deleted later)\n",
        "        self.palmiddles = np.array([tokenize(seq[50]) for seq in self.palindromes])\n",
        "        self.palmiddles = self.palmiddles.reshape([self.palmiddles.shape[0], 4])\n",
        "\n",
        "        if self.n_rubbish > 0:\n",
        "            self.rubbish = generate_rubbish(n_rubbish)\n",
        "            self.rubbish_middles = np.array([tokenize(seq[50]) for seq in self.rubbish])\n",
        "            self.rubbish_middles = self.rubbish_middles.reshape([self.rubbish_middles.shape[0], 4])\n",
        "            self.tokenized_rubbish = np.array([tokenize(seq) for seq in self.rubbish])\n",
        "            self.tokenized_rubbish = np.array([np.append(np.append(seq[:50], np.array([[0, 0, 0, 0]]), axis=0), seq[51:], axis = 0) for seq in self.tokenized_rubbish])\n",
        "\n",
        "        self.tokenized_pals = np.array([tokenize(seq) for seq in self.palindromes])\n",
        "        self.tokenized_pals = np.array([np.append(np.append(seq[:50], np.array([[0, 0, 0, 0]]), axis=0), seq[51:], axis = 0) for seq in self.tokenized_pals])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_pal + self.n_neg\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = {}\n",
        "        for pal in self.palindromes:\n",
        "            data[pal] = 1\n",
        "        for sd in self.sds:\n",
        "            data[sd] = 1\n",
        "        for neg in self.negatives:\n",
        "            data[neg] = 0        \n",
        "        return data\n",
        "    \n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2cgh6zNDWnw"
      },
      "source": [
        "t = PalNegDataset(5000, 0, 5000, n_rubbish=5000)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu4QLEOandUn",
        "outputId": "56b61689-941c-4978-f709-66722eb91d10"
      },
      "source": [
        "t.status[100:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7yic8q-zlu"
      },
      "source": [
        "trainX = t.tokenized_seq[:7000]\n",
        "testX = t.tokenized_seq[7000:9000]\n",
        "valX = t.tokenized_seq[9000:]\n",
        "trainY = t.status[:7000]\n",
        "testY = t.status[7000:9000]\n",
        "valY = t.status[9000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsJ4o5r6f4V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca44833-a598-4e67-9591-a69bc40b5ced"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqfTpdBDYxO"
      },
      "source": [
        "# палиндромы для проверки предсказания нуклеотида\n",
        "frX_train = t.tokenized_pals[:4000] + t.tokenized_rubbish[:4000] \n",
        "frY_train = t.palmiddles[:4000] + t.rubbish_middles[:4000]\n",
        "\n",
        "frX_val = t.tokenized_pals[4000:] + t.tokenized_rubbish[4000:] \n",
        "frY_val = t.palmiddles[4000:]+ t.rubbish_middles[4000:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j36VSVtzDluI",
        "outputId": "be5ff717-41a2-4c8b-a082-e360f7cb75ca"
      },
      "source": [
        "frX_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgbwMVvY5frY",
        "outputId": "1a01e189-37fc-43a9-8e45-57671e4780d6"
      },
      "source": [
        "# From find_repeat\n",
        "ms = []\n",
        "\n",
        "def run_model():\n",
        "    inp = Input((100, 4))\n",
        "    cur_p = Conv1D(filters=32, kernel_size=10, padding='SAME')(inp)\n",
        "    cur_p2 = Conv1D(filters=32, kernel_size=10, padding='SAME')(inp)\n",
        "    cur = Attention()([cur_p, inp, cur_p2])\n",
        "    cur = Flatten()(cur)\n",
        "    cur = Dense(4, activation='softmax')(cur)\n",
        "    # cur = Dense(1, activation='softmax')(cur)\n",
        "    model = Model(inp, cur)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', 'categorical_crossentropy'])    \n",
        "    model.summary()\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', patience=8, restore_best_weights=True)\n",
        "    callbacks = []\n",
        "    callbacks.append(es)\n",
        "\n",
        "    history = model.fit(frX_train, frY_train, epochs=100,  batch_size=32, \n",
        "                         validation_data=(frX_val, frY_val), \n",
        "                         callbacks=[], verbose=1)\n",
        "\n",
        "    def show(history, acc_on=True):\n",
        "        for k, v in history.history.items():\n",
        "            if int('acc' not in k) + int(acc_on) == 1:\n",
        "                plt.plot(v, label=k)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    show(history, True)\n",
        "    show(history, False)\n",
        "\n",
        "    ms.append(model)\n",
        "    # loss, test_acc, test_cat = model.evaluate(test_q, test_ans, verbose=1)\n",
        "    # return test_acc\n",
        "\n",
        "accs = [run_model() for _ in range(1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100, 4)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 100, 32)      1312        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 100, 32)      1312        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (Attention)           (None, 100, 4)       0           conv1d[0][0]                     \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 400)          0           attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            1604        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,228\n",
            "Trainable params: 4,228\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 3s 15ms/step - loss: 1.4232 - accuracy: 0.2518 - categorical_crossentropy: 1.4232 - val_loss: 1.4213 - val_accuracy: 0.2490 - val_categorical_crossentropy: 1.4213\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3941 - accuracy: 0.2732 - categorical_crossentropy: 1.3941 - val_loss: 1.3860 - val_accuracy: 0.2580 - val_categorical_crossentropy: 1.3860\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3712 - accuracy: 0.3097 - categorical_crossentropy: 1.3712 - val_loss: 1.3887 - val_accuracy: 0.2730 - val_categorical_crossentropy: 1.3887\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3628 - accuracy: 0.3125 - categorical_crossentropy: 1.3628 - val_loss: 1.3964 - val_accuracy: 0.2780 - val_categorical_crossentropy: 1.3964\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.3428 - accuracy: 0.3459 - categorical_crossentropy: 1.3428 - val_loss: 1.4119 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.4119\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3129 - accuracy: 0.3824 - categorical_crossentropy: 1.3129 - val_loss: 1.3946 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.3946\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2876 - accuracy: 0.4100 - categorical_crossentropy: 1.2876 - val_loss: 1.4009 - val_accuracy: 0.2880 - val_categorical_crossentropy: 1.4009\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2619 - accuracy: 0.4214 - categorical_crossentropy: 1.2619 - val_loss: 1.4060 - val_accuracy: 0.2850 - val_categorical_crossentropy: 1.4060\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2308 - accuracy: 0.4573 - categorical_crossentropy: 1.2308 - val_loss: 1.4325 - val_accuracy: 0.2980 - val_categorical_crossentropy: 1.4325\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.2318 - accuracy: 0.4476 - categorical_crossentropy: 1.2318 - val_loss: 1.4537 - val_accuracy: 0.2930 - val_categorical_crossentropy: 1.4537\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1910 - accuracy: 0.4735 - categorical_crossentropy: 1.1910 - val_loss: 1.4594 - val_accuracy: 0.2970 - val_categorical_crossentropy: 1.4594\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.1896 - accuracy: 0.4708 - categorical_crossentropy: 1.1896 - val_loss: 1.4537 - val_accuracy: 0.2840 - val_categorical_crossentropy: 1.4537\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1465 - accuracy: 0.5193 - categorical_crossentropy: 1.1465 - val_loss: 1.4802 - val_accuracy: 0.2800 - val_categorical_crossentropy: 1.4802\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1236 - accuracy: 0.5210 - categorical_crossentropy: 1.1236 - val_loss: 1.4988 - val_accuracy: 0.2750 - val_categorical_crossentropy: 1.4988\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1104 - accuracy: 0.5277 - categorical_crossentropy: 1.1104 - val_loss: 1.4990 - val_accuracy: 0.2800 - val_categorical_crossentropy: 1.4990\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0967 - accuracy: 0.5278 - categorical_crossentropy: 1.0967 - val_loss: 1.5186 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.5186\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0797 - accuracy: 0.5431 - categorical_crossentropy: 1.0797 - val_loss: 1.5375 - val_accuracy: 0.2970 - val_categorical_crossentropy: 1.5375\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0537 - accuracy: 0.5694 - categorical_crossentropy: 1.0537 - val_loss: 1.5593 - val_accuracy: 0.2870 - val_categorical_crossentropy: 1.5593\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0475 - accuracy: 0.5681 - categorical_crossentropy: 1.0475 - val_loss: 1.5909 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.5909\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0273 - accuracy: 0.5822 - categorical_crossentropy: 1.0273 - val_loss: 1.6039 - val_accuracy: 0.2790 - val_categorical_crossentropy: 1.6039\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0064 - accuracy: 0.5899 - categorical_crossentropy: 1.0064 - val_loss: 1.6151 - val_accuracy: 0.2870 - val_categorical_crossentropy: 1.6151\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9996 - accuracy: 0.5912 - categorical_crossentropy: 0.9996 - val_loss: 1.6433 - val_accuracy: 0.2730 - val_categorical_crossentropy: 1.6433\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9973 - accuracy: 0.5926 - categorical_crossentropy: 0.9973 - val_loss: 1.6508 - val_accuracy: 0.2790 - val_categorical_crossentropy: 1.6508\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9745 - accuracy: 0.6003 - categorical_crossentropy: 0.9745 - val_loss: 1.6725 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.6725\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9592 - accuracy: 0.6226 - categorical_crossentropy: 0.9592 - val_loss: 1.7013 - val_accuracy: 0.2920 - val_categorical_crossentropy: 1.7013\n",
            "Epoch 26/100\n",
            "124/125 [============================>.] - ETA: 0s - loss: 0.9465 - accuracy: 0.6133 - categorical_crossentropy: 0.9465"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3VeD5eg5KIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "ecc37a7c-ee66-4ccf-e6ec-a71ca688c159"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 64\n",
        "vocab_in_size = 100\n",
        "len_input_train = 4\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Input((100, 4)))\n",
        "#model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=len_input_train))\n",
        "model_lstm.add(LSTM(units))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.summary()\n",
        "\n",
        "history_lstm = model_lstm.fit(trainX, trainY, \n",
        "                              epochs=10, batch_size=BATCH_SIZE, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 64)                17664     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 17,729\n",
            "Trainable params: 17,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1203/7000 [====>.........................] - ETA: 1:36 - loss: 5.8663e-08 - accuracy: 0.5021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6e796160e392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c5q7ZrEEJ1h"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import  Conv1D, GRU, LSTM, TimeDistributed, Concatenate, Softmax, Activation, Flatten, Dense, Input, Bidirectional, Attention\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "import os\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"  # for tf 2.0\n",
        "\n",
        "main_input = Input((100, 4))\n",
        "cur_p1 = Conv1D(filters=16, kernel_size=3, padding='SAME')(main_input)\n",
        "cur_p2 = Conv1D(filters=16, kernel_size=3, padding='SAME')(main_input)\n",
        "cur1 = Attention()([cur_p1, main_input, cur_p2])\n",
        "\n",
        "cur = Concatenate()([cur1, main_input])\n",
        "cur = Bidirectional(GRU(4, return_sequences=True))(cur)\n",
        "\n",
        "d = Dense(4, activation='relu') (cur)\n",
        "d = TimeDistributed(Dense(1, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1))) (d)\n",
        "\n",
        "d = Flatten()(d)\n",
        "\n",
        "main_output = d\n",
        "model = Model(main_input, main_output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='mse', metrics=['mse', 'accuracy'])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFBPmXEm8D1G",
        "outputId": "73d28372-f610-4064-cc03-b85d536b260d"
      },
      "source": [
        "len(trainX[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEL5zPTtE7Fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "bafd2f1d-4cd7-482f-d5bf-357827db6321"
      },
      "source": [
        "history = model.fit(trainX, trainY, \n",
        "                              epochs=10, batch_size=BATCH_SIZE, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2740 - mse: 0.2539 - accuracy: 0.0000e+00 - val_loss: 0.2557 - val_mse: 0.2502 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 171s 24ms/step - loss: 0.2560 - mse: 0.2520 - accuracy: 0.0000e+00 - val_loss: 0.2542 - val_mse: 0.2514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 175s 25ms/step - loss: 0.2540 - mse: 0.2514 - accuracy: 0.0000e+00 - val_loss: 0.2563 - val_mse: 0.2537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2529 - mse: 0.2508 - accuracy: 0.0000e+00 - val_loss: 0.2550 - val_mse: 0.2528 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2528 - mse: 0.2510 - accuracy: 0.0000e+00 - val_loss: 0.2555 - val_mse: 0.2536 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "7000/7000 [==============================] - 170s 24ms/step - loss: 0.2529 - mse: 0.2514 - accuracy: 0.0000e+00 - val_loss: 0.2551 - val_mse: 0.2534 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "7000/7000 [==============================] - 171s 24ms/step - loss: 0.2525 - mse: 0.2511 - accuracy: 0.0000e+00 - val_loss: 0.2534 - val_mse: 0.2522 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "5230/7000 [=====================>........] - ETA: 41s - loss: 0.2526 - mse: 0.2512 - accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-591bce46bbc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJI6ze-T-NR5"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz7xoJpw-Wld"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e1ZxgOO-ZMN"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4o9nmJ-bTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "b99b2420-0d09-4ced-cfa2-e1ac45a28e5a"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = Input(shape=(100,4))\n",
        "embedding_layer = TokenAndPositionEmbedding(100, 4, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a67acc1f7b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtransformer_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-8-0ee9fb568205>:14 call  *\n        attn_output = self.att(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:926 __call__  **\n        input_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1137 _functional_construction_call\n        '(layer: ' + self.name + ').')\n\n    ValueError: A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: multi_head_self_attention_2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_OhRdVMFneJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "bab3a2b7-bdd0-4fdb-ec3f-6932a3b2948d"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e3bbca2ec601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n\u001b[0m\u001b[1;32m      3\u001b[0m     (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLggnVbz-QBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "feec7351-cd2f-450e-a766-e7d8e86bbf35"
      },
      "source": [
        "d_model = 512\n",
        "dff=2048\n",
        "maximum_position_encoding = 10000\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "\n",
        "scaling_factor = tf.keras.backend.constant(np.sqrt(d_model), shape = (1,1,1))\n",
        "\n",
        "\n",
        "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "# Encoder ##################################\n",
        "input = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "x = tf.keras.layers.Embedding(input_vocab_size, d_model)(input) #, mask_zero=True\n",
        "\n",
        "## positional encoding\n",
        "x = tf.keras.layers.Multiply()([x,scaling_factor])\n",
        "pos = positional_encoding(maximum_position_encoding, d_model)\n",
        "x = tf.keras.layers.Add()([x, pos[: , :tf.shape(x)[1], :]] )\n",
        "\n",
        "## self-attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(x)\n",
        "key = tf.keras.layers.Dense(d_model)(x)\n",
        "attention = tf.keras.layers.Attention()([query, value, key])                   # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## Feed Forward\n",
        "dense = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "dense = tf.keras.layers.Dense(d_model)(dense)\n",
        "x = tf.keras.layers.Add()([x , dense])                                          # residual connection\n",
        "encoder = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "# Decoder ##################################\n",
        "target = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "x = tf.keras.layers.Embedding(target_vocab_size, d_model )(target) # , mask_zero=True\n",
        "\n",
        "## positional encoding\n",
        "x = tf.keras.layers.Multiply()([x,scaling_factor])\n",
        "pos = positional_encoding(maximum_position_encoding, d_model)\n",
        "x = tf.keras.layers.Add()([x, pos[: , :tf.shape(x)[1], :] ])\n",
        "\n",
        "## self-attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(x)\n",
        "key = tf.keras.layers.Dense(d_model)(x)\n",
        "attention = tf.keras.layers.Attention(causal = True)([query, value, key])       # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])                                      # residual connection\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## encoder-decoder attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(encoder)\n",
        "key = tf.keras.layers.Dense(d_model)(encoder)\n",
        "attention = tf.keras.layers.Attention()([query, value, key])                    # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])                                      # residual connection\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## Feed Forward\n",
        "dense = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "dense = tf.keras.layers.Dense(d_model)(dense)\n",
        "x = tf.keras.layers.Add()([x , dense])                                          # residual connection\n",
        "decoder = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "######################################################\n",
        "\n",
        "x = tf.keras.layers.Dense(target_vocab_size)(decoder)\n",
        "\n",
        "base_model = tf.keras.models.Model(inputs=[input,target], outputs=x)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-22a3b85dd0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmaximum_position_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_pt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer_pt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYvKr6ocGIm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c02b97-5d1d-483b-8941-cb3541c479c4"
      },
      "source": [
        "!pip install -U transformers-keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers-keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d0/6831dd9a37863fde38772fbdd9b06287f89d1213c68d5d8a1c0f21f365c8/transformers_keras-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jieba in /usr/local/lib/python3.6/dist-packages (from transformers-keras) (0.42.1)\n",
            "Installing collected packages: transformers-keras\n",
            "Successfully installed transformers-keras-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s7eCCiMG6AA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "4f258001-35e0-48aa-d310-db19cccab737"
      },
      "source": [
        "df = pd.DataFrame({'x': trainX.flatten(), 'y': trainY.flatten()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9bb82c3ae101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2juk1YGTGX"
      },
      "source": [
        "from transformers_keras import BertTFRecordDatasetBuilder\n",
        "\n",
        "builder = BertTFRecordDatasetBuilder(max_sequence_length=128, record_option='GZIP')\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='acc')\n",
        "model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
        "model(model.dummy_inputs())\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_dataset, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP0uuUxFH8VT"
      },
      "source": [
        "class Transformer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 src_vocab_size=-1,\n",
        "                 tgt_vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "        assert src_vocab_size > 0, \"src_vocab_size must greater than 0.\"\n",
        "        assert tgt_vocab_size > 0, \"tgt_vocab_size must greater than 0.\"\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoder_layers = num_encoder_layers\n",
        "        self.num_decoder_layers = num_decoder_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.encoder = TransformerEncoder(\n",
        "            src_vocab_size, max_positions, hidden_size,\n",
        "            num_layers=num_encoder_layers, dropout_rate=dropout_rate, epsilon=epsilon)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            tgt_vocab_size, max_positions, hidden_size,\n",
        "            num_layers=num_encoder_layers, dropout_rate=dropout_rate, epsilon=epsilon)\n",
        "        self.dense = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x_ids, y_ids = inputs\n",
        "\n",
        "        def _create_padding_mask(x):\n",
        "            mask = tf.cast(tf.equal(0, x), dtype=tf.float32)\n",
        "            mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
        "            return mask\n",
        "\n",
        "        def _create_look_ahead_mask(size):\n",
        "            mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "            return mask\n",
        "\n",
        "        def _create_masks(x, y):\n",
        "            _enc_padding_mask = _create_padding_mask(x)\n",
        "            _dec_padding_mask = _create_padding_mask(x)\n",
        "            _look_ahead_mask = _create_look_ahead_mask(tf.shape(y)[1])\n",
        "            _target_padding_mask = _create_padding_mask(y)\n",
        "            combined = tf.maximum(_look_ahead_mask, _target_padding_mask)\n",
        "            return _enc_padding_mask, combined, _dec_padding_mask\n",
        "\n",
        "        enc_padding_mask, dec_look_ahead_mask, dec_padding_mask = _create_masks(x_ids, y_ids)\n",
        "\n",
        "        enc_outputs, enc_attns = self.encoder(inputs=(x_ids, enc_padding_mask))\n",
        "\n",
        "        dec_outputs, dec_attns_0, dec_attns_1 = self.decoder(\n",
        "            inputs=(y_ids, enc_outputs, dec_look_ahead_mask, dec_padding_mask))\n",
        "\n",
        "        logits = self.dense(dec_outputs)\n",
        "        return logits, enc_attns, dec_attns_0, dec_attns_1\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"src_vocab_size\": self.src_vocab_size,\n",
        "            \"tgt_vocab_size\": self.tgt_vocab_size,\n",
        "            \"max_positions\": self.max_positions,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"num_encoder_layers\": self.num_encoder_layers,\n",
        "            \"num_decoder_layers\": self.num_decoder_layers,\n",
        "            \"num_attention_heads\": self.num_attention_heads,\n",
        "            \"ffn_size\": self.ffn_size,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"epsilon\": self.epsilon,\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kA5uWOAIX5v"
      },
      "source": [
        "\n",
        "class TransformerEmbedding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, vocab_size=1, max_positions=512, embedding_size=512, dropout_rate=0.2, **kwargs):\n",
        "        super(TransformerEmbedding, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.embedding_size = embedding_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.token_embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_size)\n",
        "        self.positional_encoding = PositionalEncoding(self.max_positions, self.embedding_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids = inputs\n",
        "        token_embeddings = self.token_embedding(token_ids)\n",
        "        position_embeddings = self.positional_encoding(token_ids)\n",
        "        embedding = token_embeddings + position_embeddings\n",
        "        embedding = self.dropout(embedding, training=training)\n",
        "        return embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        conf = {\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'embedding_size': self.embedding_size,\n",
        "            'dropout_rate': self.dropout_rate\n",
        "        }\n",
        "        p = super(TransformerEmbedding, self).get_config()\n",
        "        return dict(list(p.items()) + list(conf.items()))\n",
        "\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.embedding = TransformerEmbedding(vocab_size, max_positions, hidden_size, dropout_rate)\n",
        "        self.encoders = [\n",
        "            EncoderLayer(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                ffn_size=ffn_size,\n",
        "                dropout_rate=dropout_rate,\n",
        "                epsilon=epsilon,\n",
        "                name='EncoderLayer{}'.format(i)\n",
        "            ) for i in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids, mask = inputs\n",
        "        embeddings = self.embedding(inputs=token_ids)\n",
        "\n",
        "        attn_weights = []\n",
        "        outputs = embeddings\n",
        "        for i in range(self.num_layers):\n",
        "            encoder = self.encoders[i]\n",
        "            outputs, weights = encoder(inputs=(outputs, outputs, outputs, mask))\n",
        "            attn_weights.append(weights)\n",
        "\n",
        "        return outputs, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_layers': self.num_layers,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        p = super().get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.embedding = TransformerEmbedding(vocab_size, max_positions, hidden_size, dropout_rate)\n",
        "        self.decoders = [\n",
        "            DecoderLayer(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                ffn_size=ffn_size,\n",
        "                dropout_rate=dropout_rate,\n",
        "                epsilon=epsilon,\n",
        "                name='DecoderLayer{}'.format(i)\n",
        "            ) for i in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids, enc_outputs, look_ahead_mask, padding_mask = inputs\n",
        "        embeddings = self.embedding(token_ids)\n",
        "\n",
        "        self_attn_weights, context_attn_weights = [], []\n",
        "        outputs = embeddings\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            decoder = self.decoders[i]\n",
        "            outputs, self_attn, context_attn = decoder(inputs=(outputs, enc_outputs, look_ahead_mask, padding_mask))\n",
        "            self_attn_weights.append(self_attn)\n",
        "            context_attn_weights.append(context_attn)\n",
        "\n",
        "        return outputs, self_attn_weights, context_attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_layers': self.num_layers,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        p = super(TransformerDecoder, self).get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHhwHOQkIhyw"
      },
      "source": [
        "class TransformerLearningRate(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"Learning rate schedule for Transformer.\"\"\"\n",
        "\n",
        "    def __init__(self, depth, warmup_steps=4000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            depth: Python integer, the model's hidden size\n",
        "            warmup_steps: Python integer, steps to warmup learning rate\n",
        "        \"\"\"\n",
        "        self.depth = depth\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(tf.cast(self.depth, tf.float32)) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'depth': self.depth,\n",
        "            'warmup_steps': self.warmup_steps\n",
        "        }\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZjRzg4bJAUI"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, max_positions=512, embedding_size=512, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.max_positions = max_positions\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        def _initializer(shape, dtype=tf.float32):\n",
        "            pos = np.arange(self.max_positions)[:, tf.newaxis]\n",
        "            d = np.arange(self.embedding_size)[tf.newaxis, :]\n",
        "            rads = 1 / np.power(10000, (2 * (d // 2)) / np.float32(self.embedding_size))\n",
        "            rads = pos * rads\n",
        "\n",
        "            rads[:, 0::2] = np.sin(rads[:, 0::2])\n",
        "            rads[:, 1::2] = np.cos(rads[:, 1::2])\n",
        "\n",
        "            rads = tf.cast(rads, dtype=dtype)\n",
        "            rads = tf.reshape(rads, shape=shape)\n",
        "            return rads\n",
        "\n",
        "        self.position_embedding = self.add_weight(\n",
        "            name='position_embedding',\n",
        "            shape=(self.max_positions, self.embedding_size),\n",
        "            dtype=tf.float32,\n",
        "            initializer=_initializer,\n",
        "            trainable=False)\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids = inputs\n",
        "        pos_embedding = self.position_embedding[tf.newaxis, :]\n",
        "        embedding = pos_embedding[:, :tf.shape(token_ids)[1], :]\n",
        "        return embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'max_positions': self.max_positions,\n",
        "            'embedding_size': self.embedding_size\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2-BebvSJNHM"
      },
      "source": [
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, ffn_size=2048, dropout_rate=0.2, epsilon=1e-6, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(self.hidden_size, self.ffn_size)\n",
        "        self.ffn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.ffn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        attn, attn_weights = self.attention(inputs=(query, key, value, mask))\n",
        "        attn = self.attn_dropout(attn, training=training)\n",
        "        attn = self.attn_layer_norm(query + attn)\n",
        "\n",
        "        ffn = self.ffn(attn)\n",
        "        ffn = self.ffn_dropout(ffn, training=training)\n",
        "        ffn = self.ffn_layer_norm(ffn + attn)\n",
        "\n",
        "        return ffn, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, ffn_size=2048, dropout_rate=0.2, epsilon=1e-6, **kwargs):\n",
        "        super(DecoderLayer, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.self_attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.self_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.context_attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.context_attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.context_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(self.hidden_size, self.ffn_size)\n",
        "        self.ffn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.ffn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x, enc_outputs, look_ahead_mask, padding_mask = inputs\n",
        "\n",
        "        attn1, attn1_weights = self.self_attention(inputs=(x, x, x, look_ahead_mask))\n",
        "        attn1 = self.self_attn_dropout(attn1, training=training)\n",
        "        output1 = self.self_attn_layer_norm(attn1 + x)\n",
        "\n",
        "        attn2, attn2_weights = self.context_attention(inputs=(output1, enc_outputs, enc_outputs, padding_mask))\n",
        "        attn2 = self.context_attn_dropout(attn2, training=training)\n",
        "        output2 = self.context_attn_layer_norm(attn2 + output1)\n",
        "\n",
        "        ffn = self.ffn(output2)\n",
        "        ffn = self.ffn_dropout(ffn, training=training)\n",
        "        ffn = self.ffn_layer_norm(ffn + attn2)\n",
        "\n",
        "        return ffn, attn1_weights, attn2_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        base = super(DecoderLayer, self).get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMTQedF8JhhI"
      },
      "source": [
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        assert self.hidden_size % self.num_attention_heads == 0\n",
        "\n",
        "        self.query_weight = tf.keras.layers.Dense(self.hidden_size, name='query')\n",
        "        self.key_weight = tf.keras.layers.Dense(self.hidden_size, name='key')\n",
        "        self.value_weight = tf.keras.layers.Dense(self.hidden_size, name='value')\n",
        "\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(self.hidden_size, name='dense')\n",
        "\n",
        "    def _split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.hidden_size // self.num_attention_heads))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        query = self._split_heads(self.query_weight(query), batch_size)\n",
        "        key = self._split_heads(self.key_weight(key), batch_size)\n",
        "        value = self._split_heads(self.value_weight(value), batch_size)\n",
        "\n",
        "        context, attn_weights = self.attention(inputs=(query, key, value, mask))\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])\n",
        "        context = tf.reshape(context, [batch_size, -1, self.hidden_size])\n",
        "        output = self.dense(context)\n",
        "        return output, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Csj6knJpwd"
      },
      "source": [
        "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        query = tf.cast(query, dtype=self.dtype)\n",
        "        key = tf.cast(key, dtype=self.dtype)\n",
        "        value = tf.cast(value, dtype=self.dtype)\n",
        "\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dk = tf.cast(tf.shape(query)[-1], tf.float32)\n",
        "        score = score / tf.math.sqrt(dk)\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=self.dtype)\n",
        "            score += mask * -10000.0\n",
        "        attn_weights = tf.nn.softmax(score, axis=-1)\n",
        "        context = tf.matmul(attn_weights, value)\n",
        "        return context, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "\n",
        "class PointWiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, ffn_size=2048, **kwargs):\n",
        "        super(PointWiseFeedForwardNetwork, self).__init__(**kwargs)\n",
        "        self.ffn_size = ffn_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dense1 = tf.keras.layers.Dense(self.ffn_size, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(self.hidden_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        outputs = self.dense2(self.dense1(inputs))\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'hidden_size': self.hidden_size,\n",
        "        }\n",
        "        p = super(PointWiseFeedForwardNetwork, self).get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBHA83CH-BH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "05552164-58c8-4203-e925-06d5bb200339"
      },
      "source": [
        "x = tf.keras.layers.Input((None, 100, 4), dtype=tf.int32, name='x')\n",
        "y = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='y')\n",
        "model = Transformer(src_vocab_size=4,\n",
        "                 tgt_vocab_size=4)\n",
        "inputs=Input(shape=(100,4))\n",
        "logits, _, _, _ = model(inputs=inputs)\n",
        "probs = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.nn.softmax(x), name='probs')(logits)\n",
        "\n",
        "model = tf.keras.Model(inputs=[x, y], outputs=[probs])\n",
        "\n",
        "lr = 0.1 #TransformerLearningRate(config.get('hidden_size', 512))\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(name='loss', from_logits=False),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='acc')],\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    <ipython-input-29-c8c5ccfc8e75>:37 call  *\n        x_ids, y_ids = inputs\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:479 _disallow_in_graph_mode\n        \" this function with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ccde5946f3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                  tgt_vocab_size=4)\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m probs = tf.keras.layers.Lambda(\n\u001b[1;32m      8\u001b[0m     lambda x: tf.nn.softmax(x), name='probs')(logits)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                             \u001b[0;34m'dynamic. Pass `dynamic=True` to the class '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                             \u001b[0;34m'constructor.\\nEncountered error:\\n\"\"\"\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                             '\\n\"\"\"')\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m           \u001b[0;31m# We will use static shape inference to return symbolic tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\nEncountered error:\n\"\"\"\nin user code:\n\n    <ipython-input-29-c8c5ccfc8e75>:37 call  *\n        x_ids, y_ids = inputs\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:479 _disallow_in_graph_mode\n        \" this function with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n\n\"\"\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ125GE0KTYD"
      },
      "source": [
        "epochs=10,\n",
        "ckpt_steps=2000,\n",
        "export_steps=5000,\n",
        "callbacks=None,\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuTWJ852LCok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "aa91de12-63f4-4395-f144-ee68fe67a4e2"
      },
      "source": [
        "history = model.fit(trainX, trainY, \n",
        "                              epochs=10, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"x_10:0\", shape=(None, 100), dtype=int32), but it was called on an input with incompatible shape (None, 100, 4).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-21a093d94e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"probs/Softmax_2:0\", shape=(None, 4, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN_CQOS9KltM"
      },
      "source": [
        "        history = self.model.fit(\n",
        "            train_dataset,\n",
        "            validation_data=valid_dataset,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}