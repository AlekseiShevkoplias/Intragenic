{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CurrentPalGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlekseiShevkoplias/Intragenic/blob/rubbish/CurrentPalGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km42r3SmeE_p"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate, Lambda, Add, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igrWDv1c2ano"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM, Input\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "COMPLEMENT = {\n",
        "    'A': 'T',\n",
        "    'G': 'C',\n",
        "    'T': 'A', \n",
        "    'C': 'G'\n",
        "}\n",
        "\n",
        "NUC = ['A', 'T', 'G', 'C']\n",
        "\n",
        "TOKENS = {\n",
        "    'A': [1, 0, 0, 0],\n",
        "    'G': [0, 1, 0, 0],\n",
        "    'T': [0, 0, 1, 0], \n",
        "    'C': [0, 0, 0, 1], \n",
        "    'X': [0, 0, 0, 0]\n",
        "}\n",
        "\n",
        "def tokenize(seq):\n",
        "    tokenized = []\n",
        "    for nuc in seq:\n",
        "        tokenized.append(TOKENS[nuc])\n",
        "    return tokenized\n",
        "\n",
        "def generate_palindromes(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA palindromes.\n",
        "    n: the number of palindromes to be generated\n",
        "    \"\"\"\n",
        "    palindromes = []\n",
        "    for j in range(n):\n",
        "  \n",
        "        pal_length = random.randint(2, 10)\n",
        "\n",
        "        palindrome = ''\n",
        "        for i in range(50 - pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "        for i in range(pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "        for i in range(pal_length - 1, -1, -1):\n",
        "            palindrome += COMPLEMENT[palindrome[i]]\n",
        "        \n",
        "        for i in range(50 - pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "\n",
        "        palindromes.append(palindrome)\n",
        "\n",
        "    return palindromes\n",
        "\n",
        "\n",
        "def generate_sd(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA with inserted SD.\n",
        "    n: the number of palindromes to be generated.\n",
        "    \"\"\"\n",
        "    sds = []\n",
        "    for i in range(n):\n",
        "        sd = ''\n",
        "        for i in range(47):\n",
        "            sd += random.choice(NUC)\n",
        "        sd += 'AGGAGG'\n",
        "        for i in range(47):\n",
        "            sd += random.choice(NUC)\n",
        "\n",
        "        sds.append(sd)\n",
        "\n",
        "    return sds\n",
        "\n",
        "def test_sd(seq):\n",
        "    if 'AGGAGG' in seq[47:54]:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def test_palindrome(seq):\n",
        "    \"\"\"\n",
        "    Tests whether the seq is a DNA palindrome or not.\n",
        "    seq: A str object with the DNA sequence\n",
        "    return: True if seq is a palindrome and False if not\n",
        "    \"\"\"\n",
        "    assert isinstance(seq, str)\n",
        "    complementary = ''\n",
        "    for i in range(len(seq)//2 - 1, -1, -1):\n",
        "        complementary += COMPLEMENT[seq[i]]\n",
        "    return complementary == seq[len(seq)//2:]\n",
        "\n",
        "def generate_negatives(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA non-palindromes.\n",
        "    n: the number of negatives to be generated\n",
        "    \"\"\"\n",
        "    negs = []\n",
        "    for j in range(n):\n",
        "        is_palindrome = True\n",
        "        neg_length = random.randint(2, 10) * 2\n",
        "        preneg = ''\n",
        "\n",
        "        for i in range(50 - neg_length//2):\n",
        "            preneg += random.choice(NUC)\n",
        "\n",
        "        while is_palindrome:\n",
        "            \n",
        "\n",
        "            neg = ''\n",
        "\n",
        "            for i in range(neg_length):\n",
        "                neg += random.choice(NUC)\n",
        "\n",
        "            is_palindrome = test_palindrome(neg) or test_sd(neg)\n",
        "        neg = preneg + neg\n",
        "\n",
        "        for i in range(50 - neg_length//2):\n",
        "            neg += random.choice(NUC)\n",
        "\n",
        "        negs.append(neg)\n",
        "\n",
        "    return negs\n",
        "\n",
        "def generate_rubbish(n):\n",
        "    \"\"\"\n",
        "    Negative with X in the middle\n",
        "    \"\"\"\n",
        "    rubbishes = []\n",
        "    for i in range(n):\n",
        "        rubbish = ''\n",
        "        for i in range(50):\n",
        "            rubbish += random.choice(NUC)\n",
        "        rubbish += 'X'\n",
        "        for i in range(49):\n",
        "            rubbish += random.choice(NUC)\n",
        "        rubbishes.append(rubbish)\n",
        "\n",
        "    return rubbishes\n",
        "\n",
        "class PalNegDataset:\n",
        "    def __init__(self, n_pal, n_sd, n_neg, n_rubbish = 0):\n",
        "        \n",
        "        self.n_pal = n_pal\n",
        "        self.n_sd = n_sd\n",
        "        self.n_neg = n_neg\n",
        "        self.n_rubbish = n_rubbish\n",
        "\n",
        "        self.palindromes = generate_palindromes(n_pal)\n",
        "        self.sds = generate_sd(n_sd)\n",
        "        self.negatives = generate_negatives(n_neg)\n",
        "        self.data = self.generate_data()\n",
        "        self.sequences = self.palindromes + self.sds + self.negatives\n",
        "\n",
        "        random.shuffle(self.sequences)\n",
        "        self.status = K.constant([self.data[key] for key in self.sequences])\n",
        "        self.tokenized_seq = np.array([tokenize(seq) for seq in self.sequences])\n",
        "        self.middles = np.array([tokenize(seq[50]) for seq in self.sequences])\n",
        "\n",
        "        # different stuff (likely will be deleted later)\n",
        "        self.palmiddles = np.array([tokenize(seq[50]) for seq in self.palindromes])\n",
        "        self.palmiddles = self.palmiddles.reshape([self.palmiddles.shape[0], 4])\n",
        "\n",
        "        if self.n_rubbish > 0:\n",
        "            self.rubbish = generate_rubbish(n_rubbish)\n",
        "            self.rubbish_middles = np.array([tokenize(seq[50]) for seq in self.rubbish])\n",
        "            self.rubbish_middles = self.rubbish_middles.reshape([self.rubbish_middles.shape[0], 4])\n",
        "            self.tokenized_rubbish = np.array([tokenize(seq) for seq in self.rubbish])\n",
        "            self.tokenized_rubbish = np.array([np.append(np.append(seq[:50], np.array([[0, 0, 0, 0]]), axis=0), seq[51:], axis = 0) for seq in self.tokenized_rubbish])\n",
        "\n",
        "        self.tokenized_pals = np.array([tokenize(seq) for seq in self.palindromes])\n",
        "        self.tokenized_pals = np.array([np.append(np.append(seq[:50], np.array([[0, 0, 0, 0]]), axis=0), seq[51:], axis = 0) for seq in self.tokenized_pals])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_pal + self.n_neg\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = {}\n",
        "        for pal in self.palindromes:\n",
        "            data[pal] = 1\n",
        "        for sd in self.sds:\n",
        "            data[sd] = 1\n",
        "        for neg in self.negatives:\n",
        "            data[neg] = 0        \n",
        "        return data\n",
        "    \n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2cgh6zNDWnw"
      },
      "source": [
        "t = PalNegDataset(5000, 0, 5000, n_rubbish=5000)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu4QLEOandUn",
        "outputId": "56b61689-941c-4978-f709-66722eb91d10"
      },
      "source": [
        "t.status[100:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7yic8q-zlu"
      },
      "source": [
        "trainX = t.tokenized_seq[:7000]\n",
        "testX = t.tokenized_seq[7000:9000]\n",
        "valX = t.tokenized_seq[9000:]\n",
        "trainY = t.status[:7000]\n",
        "testY = t.status[7000:9000]\n",
        "valY = t.status[9000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsJ4o5r6f4V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca44833-a598-4e67-9591-a69bc40b5ced"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqfTpdBDYxO"
      },
      "source": [
        "# палиндромы для проверки предсказания нуклеотида\n",
        "frX_train = t.tokenized_pals[:4000]  # + t.tokenized_rubbish[:4000] \n",
        "frY_train = t.palmiddles[:4000] # + t.rubbish_middles[:4000]\n",
        "\n",
        "frX_val = t.tokenized_pals[4000:] #  + t.tokenized_rubbish[4000:] \n",
        "frY_val = t.palmiddles[4000:] #+ t.rubbish_middles[4000:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j36VSVtzDluI",
        "outputId": "be5ff717-41a2-4c8b-a082-e360f7cb75ca"
      },
      "source": [
        "frX_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tgbwMVvY5frY",
        "outputId": "fdb95d1d-ceb4-46b4-ecfe-1973b9fefde5"
      },
      "source": [
        "# From find_repeat\n",
        "ms = []\n",
        "\n",
        "def run_model():\n",
        "    inp = Input((100, 4))\n",
        "    cur_p = Conv1D(filters=32, kernel_size=10, padding='SAME')(inp)\n",
        "    cur_p2 = Conv1D(filters=32, kernel_size=10, padding='SAME')(inp)\n",
        "    cur = Attention()([cur_p, inp, cur_p2])\n",
        "    cur = Flatten()(cur)\n",
        "    cur = Dense(4, activation='softmax')(cur)\n",
        "    # cur = Dense(1, activation='softmax')(cur)\n",
        "    model = Model(inp, cur)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', 'categorical_crossentropy'])    \n",
        "    model.summary()\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', patience=8, restore_best_weights=True)\n",
        "    callbacks = []\n",
        "    callbacks.append(es)\n",
        "\n",
        "    history = model.fit(frX_train, frY_train, epochs=100,  batch_size=32, \n",
        "                         validation_data=(frX_val, frY_val), \n",
        "                         callbacks=[], verbose=1)\n",
        "\n",
        "    def show(history, acc_on=True):\n",
        "        for k, v in history.history.items():\n",
        "            if int('acc' not in k) + int(acc_on) == 1:\n",
        "                plt.plot(v, label=k)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    show(history, True)\n",
        "    show(history, False)\n",
        "\n",
        "    ms.append(model)\n",
        "    # loss, test_acc, test_cat = model.evaluate(test_q, test_ans, verbose=1)\n",
        "    # return test_acc\n",
        "\n",
        "accs = [run_model() for _ in range(1)]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 100, 4)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 100, 32)      1312        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 100, 32)      1312        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         (None, 100, 4)       0           conv1d_2[0][0]                   \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 400)          0           attention_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            1604        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,228\n",
            "Trainable params: 4,228\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 1.4000 - accuracy: 0.2474 - categorical_crossentropy: 1.4000 - val_loss: 1.3844 - val_accuracy: 0.2410 - val_categorical_crossentropy: 1.3844\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3793 - accuracy: 0.2756 - categorical_crossentropy: 1.3793 - val_loss: 1.3740 - val_accuracy: 0.2800 - val_categorical_crossentropy: 1.3740\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3625 - accuracy: 0.3163 - categorical_crossentropy: 1.3625 - val_loss: 1.3550 - val_accuracy: 0.3340 - val_categorical_crossentropy: 1.3550\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3450 - accuracy: 0.3388 - categorical_crossentropy: 1.3450 - val_loss: 1.3388 - val_accuracy: 0.3340 - val_categorical_crossentropy: 1.3388\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3115 - accuracy: 0.3690 - categorical_crossentropy: 1.3115 - val_loss: 1.3098 - val_accuracy: 0.3590 - val_categorical_crossentropy: 1.3098\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2790 - accuracy: 0.4125 - categorical_crossentropy: 1.2790 - val_loss: 1.2868 - val_accuracy: 0.3920 - val_categorical_crossentropy: 1.2868\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2459 - accuracy: 0.4451 - categorical_crossentropy: 1.2459 - val_loss: 1.2924 - val_accuracy: 0.3610 - val_categorical_crossentropy: 1.2924\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2326 - accuracy: 0.4428 - categorical_crossentropy: 1.2326 - val_loss: 1.2814 - val_accuracy: 0.4200 - val_categorical_crossentropy: 1.2814\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2099 - accuracy: 0.4566 - categorical_crossentropy: 1.2099 - val_loss: 1.2823 - val_accuracy: 0.3880 - val_categorical_crossentropy: 1.2823\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.1969 - accuracy: 0.4698 - categorical_crossentropy: 1.1969 - val_loss: 1.2627 - val_accuracy: 0.4230 - val_categorical_crossentropy: 1.2627\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.1613 - accuracy: 0.5001 - categorical_crossentropy: 1.1613 - val_loss: 1.2647 - val_accuracy: 0.4250 - val_categorical_crossentropy: 1.2647\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1329 - accuracy: 0.5207 - categorical_crossentropy: 1.1329 - val_loss: 1.2530 - val_accuracy: 0.4240 - val_categorical_crossentropy: 1.2530\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1261 - accuracy: 0.5167 - categorical_crossentropy: 1.1261 - val_loss: 1.2505 - val_accuracy: 0.4170 - val_categorical_crossentropy: 1.2505\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.1066 - accuracy: 0.5412 - categorical_crossentropy: 1.1066 - val_loss: 1.2716 - val_accuracy: 0.4090 - val_categorical_crossentropy: 1.2716\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.1054 - accuracy: 0.5212 - categorical_crossentropy: 1.1054 - val_loss: 1.2648 - val_accuracy: 0.4290 - val_categorical_crossentropy: 1.2648\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.0641 - accuracy: 0.5482 - categorical_crossentropy: 1.0641 - val_loss: 1.2676 - val_accuracy: 0.4070 - val_categorical_crossentropy: 1.2676\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.0512 - accuracy: 0.5723 - categorical_crossentropy: 1.0512 - val_loss: 1.2730 - val_accuracy: 0.4120 - val_categorical_crossentropy: 1.2730\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0439 - accuracy: 0.5683 - categorical_crossentropy: 1.0439 - val_loss: 1.2798 - val_accuracy: 0.4160 - val_categorical_crossentropy: 1.2798\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.0341 - accuracy: 0.5782 - categorical_crossentropy: 1.0341 - val_loss: 1.2843 - val_accuracy: 0.4160 - val_categorical_crossentropy: 1.2843\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.0234 - accuracy: 0.5764 - categorical_crossentropy: 1.0234 - val_loss: 1.3043 - val_accuracy: 0.4060 - val_categorical_crossentropy: 1.3043\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.0150 - accuracy: 0.5861 - categorical_crossentropy: 1.0150 - val_loss: 1.2978 - val_accuracy: 0.4200 - val_categorical_crossentropy: 1.2978\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9750 - accuracy: 0.6116 - categorical_crossentropy: 0.9750 - val_loss: 1.3261 - val_accuracy: 0.4110 - val_categorical_crossentropy: 1.3261\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9761 - accuracy: 0.6030 - categorical_crossentropy: 0.9761 - val_loss: 1.3189 - val_accuracy: 0.4070 - val_categorical_crossentropy: 1.3189\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9601 - accuracy: 0.6178 - categorical_crossentropy: 0.9601 - val_loss: 1.3323 - val_accuracy: 0.4170 - val_categorical_crossentropy: 1.3323\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9572 - accuracy: 0.6186 - categorical_crossentropy: 0.9572 - val_loss: 1.3406 - val_accuracy: 0.4210 - val_categorical_crossentropy: 1.3406\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9579 - accuracy: 0.6087 - categorical_crossentropy: 0.9579 - val_loss: 1.3602 - val_accuracy: 0.4060 - val_categorical_crossentropy: 1.3602\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9435 - accuracy: 0.6166 - categorical_crossentropy: 0.9435 - val_loss: 1.3703 - val_accuracy: 0.3960 - val_categorical_crossentropy: 1.3703\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9244 - accuracy: 0.6305 - categorical_crossentropy: 0.9244 - val_loss: 1.3853 - val_accuracy: 0.3980 - val_categorical_crossentropy: 1.3853\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9278 - accuracy: 0.6346 - categorical_crossentropy: 0.9278 - val_loss: 1.3772 - val_accuracy: 0.4140 - val_categorical_crossentropy: 1.3772\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9037 - accuracy: 0.6568 - categorical_crossentropy: 0.9037 - val_loss: 1.3884 - val_accuracy: 0.4140 - val_categorical_crossentropy: 1.3884\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8921 - accuracy: 0.6462 - categorical_crossentropy: 0.8921 - val_loss: 1.4090 - val_accuracy: 0.4080 - val_categorical_crossentropy: 1.4090\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8986 - accuracy: 0.6450 - categorical_crossentropy: 0.8986 - val_loss: 1.4087 - val_accuracy: 0.4040 - val_categorical_crossentropy: 1.4087\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8897 - accuracy: 0.6499 - categorical_crossentropy: 0.8897 - val_loss: 1.4205 - val_accuracy: 0.4050 - val_categorical_crossentropy: 1.4205\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8555 - accuracy: 0.6635 - categorical_crossentropy: 0.8555 - val_loss: 1.4420 - val_accuracy: 0.4050 - val_categorical_crossentropy: 1.4420\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8641 - accuracy: 0.6624 - categorical_crossentropy: 0.8641 - val_loss: 1.4601 - val_accuracy: 0.3950 - val_categorical_crossentropy: 1.4601\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8651 - accuracy: 0.6664 - categorical_crossentropy: 0.8651 - val_loss: 1.4608 - val_accuracy: 0.3870 - val_categorical_crossentropy: 1.4608\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8330 - accuracy: 0.6761 - categorical_crossentropy: 0.8330 - val_loss: 1.4751 - val_accuracy: 0.4040 - val_categorical_crossentropy: 1.4751\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8455 - accuracy: 0.6698 - categorical_crossentropy: 0.8455 - val_loss: 1.4806 - val_accuracy: 0.3990 - val_categorical_crossentropy: 1.4806\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8486 - accuracy: 0.6664 - categorical_crossentropy: 0.8486 - val_loss: 1.4874 - val_accuracy: 0.4020 - val_categorical_crossentropy: 1.4874\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8439 - accuracy: 0.6696 - categorical_crossentropy: 0.8439 - val_loss: 1.5080 - val_accuracy: 0.3940 - val_categorical_crossentropy: 1.5080\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8075 - accuracy: 0.6893 - categorical_crossentropy: 0.8075 - val_loss: 1.5103 - val_accuracy: 0.3910 - val_categorical_crossentropy: 1.5103\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8201 - accuracy: 0.6861 - categorical_crossentropy: 0.8201 - val_loss: 1.5227 - val_accuracy: 0.3860 - val_categorical_crossentropy: 1.5227\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8157 - accuracy: 0.6829 - categorical_crossentropy: 0.8157 - val_loss: 1.5376 - val_accuracy: 0.3840 - val_categorical_crossentropy: 1.5376\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7999 - accuracy: 0.6849 - categorical_crossentropy: 0.7999 - val_loss: 1.5378 - val_accuracy: 0.3810 - val_categorical_crossentropy: 1.5378\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8122 - accuracy: 0.6789 - categorical_crossentropy: 0.8122 - val_loss: 1.5565 - val_accuracy: 0.3800 - val_categorical_crossentropy: 1.5565\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7848 - accuracy: 0.6994 - categorical_crossentropy: 0.7848 - val_loss: 1.5721 - val_accuracy: 0.3800 - val_categorical_crossentropy: 1.5721\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8013 - accuracy: 0.6832 - categorical_crossentropy: 0.8013 - val_loss: 1.5685 - val_accuracy: 0.3870 - val_categorical_crossentropy: 1.5685\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7942 - accuracy: 0.7007 - categorical_crossentropy: 0.7942 - val_loss: 1.5775 - val_accuracy: 0.3760 - val_categorical_crossentropy: 1.5775\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7820 - accuracy: 0.7027 - categorical_crossentropy: 0.7820 - val_loss: 1.5846 - val_accuracy: 0.3800 - val_categorical_crossentropy: 1.5846\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7822 - accuracy: 0.6883 - categorical_crossentropy: 0.7822 - val_loss: 1.6021 - val_accuracy: 0.3700 - val_categorical_crossentropy: 1.6021\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7656 - accuracy: 0.7031 - categorical_crossentropy: 0.7656 - val_loss: 1.6142 - val_accuracy: 0.3740 - val_categorical_crossentropy: 1.6142\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7598 - accuracy: 0.6985 - categorical_crossentropy: 0.7598 - val_loss: 1.6272 - val_accuracy: 0.3820 - val_categorical_crossentropy: 1.6272\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7458 - accuracy: 0.7137 - categorical_crossentropy: 0.7458 - val_loss: 1.6286 - val_accuracy: 0.3760 - val_categorical_crossentropy: 1.6286\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7787 - accuracy: 0.6968 - categorical_crossentropy: 0.7787 - val_loss: 1.6492 - val_accuracy: 0.3740 - val_categorical_crossentropy: 1.6492\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7611 - accuracy: 0.7063 - categorical_crossentropy: 0.7611 - val_loss: 1.6545 - val_accuracy: 0.3760 - val_categorical_crossentropy: 1.6545\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7692 - accuracy: 0.7000 - categorical_crossentropy: 0.7692 - val_loss: 1.6759 - val_accuracy: 0.3800 - val_categorical_crossentropy: 1.6759\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7266 - accuracy: 0.7203 - categorical_crossentropy: 0.7266 - val_loss: 1.6804 - val_accuracy: 0.3720 - val_categorical_crossentropy: 1.6804\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7181 - accuracy: 0.7163 - categorical_crossentropy: 0.7181 - val_loss: 1.6809 - val_accuracy: 0.3680 - val_categorical_crossentropy: 1.6809\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7404 - accuracy: 0.7055 - categorical_crossentropy: 0.7404 - val_loss: 1.7024 - val_accuracy: 0.3760 - val_categorical_crossentropy: 1.7024\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7382 - accuracy: 0.7150 - categorical_crossentropy: 0.7382 - val_loss: 1.7186 - val_accuracy: 0.3750 - val_categorical_crossentropy: 1.7186\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7104 - accuracy: 0.7283 - categorical_crossentropy: 0.7104 - val_loss: 1.7108 - val_accuracy: 0.3730 - val_categorical_crossentropy: 1.7108\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7214 - accuracy: 0.7146 - categorical_crossentropy: 0.7214 - val_loss: 1.7205 - val_accuracy: 0.3710 - val_categorical_crossentropy: 1.7205\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7320 - accuracy: 0.7148 - categorical_crossentropy: 0.7320 - val_loss: 1.7478 - val_accuracy: 0.3670 - val_categorical_crossentropy: 1.7478\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7425 - accuracy: 0.7108 - categorical_crossentropy: 0.7425 - val_loss: 1.7493 - val_accuracy: 0.3730 - val_categorical_crossentropy: 1.7493\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7046 - accuracy: 0.7230 - categorical_crossentropy: 0.7046 - val_loss: 1.7515 - val_accuracy: 0.3740 - val_categorical_crossentropy: 1.7515\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7073 - accuracy: 0.7324 - categorical_crossentropy: 0.7073 - val_loss: 1.7658 - val_accuracy: 0.3820 - val_categorical_crossentropy: 1.7658\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7184 - accuracy: 0.7172 - categorical_crossentropy: 0.7184 - val_loss: 1.7737 - val_accuracy: 0.3680 - val_categorical_crossentropy: 1.7737\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6910 - accuracy: 0.7312 - categorical_crossentropy: 0.6910 - val_loss: 1.7869 - val_accuracy: 0.3740 - val_categorical_crossentropy: 1.7869\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6859 - accuracy: 0.7274 - categorical_crossentropy: 0.6859 - val_loss: 1.7951 - val_accuracy: 0.3670 - val_categorical_crossentropy: 1.7951\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7032 - accuracy: 0.7236 - categorical_crossentropy: 0.7032 - val_loss: 1.7981 - val_accuracy: 0.3770 - val_categorical_crossentropy: 1.7981\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6857 - accuracy: 0.7270 - categorical_crossentropy: 0.6857 - val_loss: 1.8132 - val_accuracy: 0.3750 - val_categorical_crossentropy: 1.8132\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6960 - accuracy: 0.7296 - categorical_crossentropy: 0.6960 - val_loss: 1.8265 - val_accuracy: 0.3720 - val_categorical_crossentropy: 1.8265\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6579 - accuracy: 0.7481 - categorical_crossentropy: 0.6579 - val_loss: 1.8395 - val_accuracy: 0.3690 - val_categorical_crossentropy: 1.8395\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6755 - accuracy: 0.7308 - categorical_crossentropy: 0.6755 - val_loss: 1.8634 - val_accuracy: 0.3650 - val_categorical_crossentropy: 1.8634\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6706 - accuracy: 0.7438 - categorical_crossentropy: 0.6706 - val_loss: 1.8673 - val_accuracy: 0.3670 - val_categorical_crossentropy: 1.8673\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6700 - accuracy: 0.7446 - categorical_crossentropy: 0.6700 - val_loss: 1.8742 - val_accuracy: 0.3770 - val_categorical_crossentropy: 1.8742\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6593 - accuracy: 0.7505 - categorical_crossentropy: 0.6593 - val_loss: 1.8901 - val_accuracy: 0.3700 - val_categorical_crossentropy: 1.8901\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6367 - accuracy: 0.7574 - categorical_crossentropy: 0.6367 - val_loss: 1.8901 - val_accuracy: 0.3630 - val_categorical_crossentropy: 1.8901\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6657 - accuracy: 0.7403 - categorical_crossentropy: 0.6657 - val_loss: 1.9164 - val_accuracy: 0.3580 - val_categorical_crossentropy: 1.9164\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6660 - accuracy: 0.7387 - categorical_crossentropy: 0.6660 - val_loss: 1.9197 - val_accuracy: 0.3700 - val_categorical_crossentropy: 1.9197\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6607 - accuracy: 0.7434 - categorical_crossentropy: 0.6607 - val_loss: 1.9369 - val_accuracy: 0.3490 - val_categorical_crossentropy: 1.9369\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6337 - accuracy: 0.7651 - categorical_crossentropy: 0.6337 - val_loss: 1.9436 - val_accuracy: 0.3670 - val_categorical_crossentropy: 1.9436\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6294 - accuracy: 0.7560 - categorical_crossentropy: 0.6294 - val_loss: 1.9530 - val_accuracy: 0.3680 - val_categorical_crossentropy: 1.9530\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6360 - accuracy: 0.7566 - categorical_crossentropy: 0.6360 - val_loss: 1.9629 - val_accuracy: 0.3670 - val_categorical_crossentropy: 1.9629\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6526 - accuracy: 0.7418 - categorical_crossentropy: 0.6526 - val_loss: 1.9770 - val_accuracy: 0.3600 - val_categorical_crossentropy: 1.9770\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6447 - accuracy: 0.7494 - categorical_crossentropy: 0.6447 - val_loss: 1.9865 - val_accuracy: 0.3560 - val_categorical_crossentropy: 1.9865\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6314 - accuracy: 0.7667 - categorical_crossentropy: 0.6314 - val_loss: 1.9966 - val_accuracy: 0.3670 - val_categorical_crossentropy: 1.9966\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6238 - accuracy: 0.7631 - categorical_crossentropy: 0.6238 - val_loss: 2.0029 - val_accuracy: 0.3700 - val_categorical_crossentropy: 2.0029\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6120 - accuracy: 0.7734 - categorical_crossentropy: 0.6120 - val_loss: 2.0166 - val_accuracy: 0.3590 - val_categorical_crossentropy: 2.0166\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6267 - accuracy: 0.7603 - categorical_crossentropy: 0.6267 - val_loss: 2.0286 - val_accuracy: 0.3610 - val_categorical_crossentropy: 2.0286\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6305 - accuracy: 0.7512 - categorical_crossentropy: 0.6305 - val_loss: 2.0499 - val_accuracy: 0.3570 - val_categorical_crossentropy: 2.0499\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6401 - accuracy: 0.7527 - categorical_crossentropy: 0.6401 - val_loss: 2.0533 - val_accuracy: 0.3580 - val_categorical_crossentropy: 2.0533\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6306 - accuracy: 0.7604 - categorical_crossentropy: 0.6306 - val_loss: 2.0570 - val_accuracy: 0.3680 - val_categorical_crossentropy: 2.0570\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6365 - accuracy: 0.7472 - categorical_crossentropy: 0.6365 - val_loss: 2.0721 - val_accuracy: 0.3670 - val_categorical_crossentropy: 2.0721\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6279 - accuracy: 0.7523 - categorical_crossentropy: 0.6279 - val_loss: 2.0763 - val_accuracy: 0.3650 - val_categorical_crossentropy: 2.0763\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6334 - accuracy: 0.7579 - categorical_crossentropy: 0.6334 - val_loss: 2.0896 - val_accuracy: 0.3610 - val_categorical_crossentropy: 2.0896\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.5993 - accuracy: 0.7742 - categorical_crossentropy: 0.5993 - val_loss: 2.1006 - val_accuracy: 0.3600 - val_categorical_crossentropy: 2.1006\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6105 - accuracy: 0.7595 - categorical_crossentropy: 0.6105 - val_loss: 2.1067 - val_accuracy: 0.3680 - val_categorical_crossentropy: 2.1067\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6019 - accuracy: 0.7715 - categorical_crossentropy: 0.6019 - val_loss: 2.1373 - val_accuracy: 0.3610 - val_categorical_crossentropy: 2.1373\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6211 - accuracy: 0.7756 - categorical_crossentropy: 0.6211 - val_loss: 2.1303 - val_accuracy: 0.3640 - val_categorical_crossentropy: 2.1303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3VeD5eg5KIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "ecc37a7c-ee66-4ccf-e6ec-a71ca688c159"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 64\n",
        "vocab_in_size = 100\n",
        "len_input_train = 4\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Input((100, 4)))\n",
        "#model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=len_input_train))\n",
        "model_lstm.add(LSTM(units))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.summary()\n",
        "\n",
        "history_lstm = model_lstm.fit(trainX, trainY, \n",
        "                              epochs=10, batch_size=BATCH_SIZE, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 64)                17664     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 17,729\n",
            "Trainable params: 17,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1203/7000 [====>.........................] - ETA: 1:36 - loss: 5.8663e-08 - accuracy: 0.5021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6e796160e392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c5q7ZrEEJ1h"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import  Conv1D, GRU, LSTM, TimeDistributed, Concatenate, Softmax, Activation, Flatten, Dense, Input, Bidirectional, Attention\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "import os\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"  # for tf 2.0\n",
        "\n",
        "main_input = Input((100, 4))\n",
        "cur_p1 = Conv1D(filters=16, kernel_size=3, padding='SAME')(main_input)\n",
        "cur_p2 = Conv1D(filters=16, kernel_size=3, padding='SAME')(main_input)\n",
        "cur1 = Attention()([cur_p1, main_input, cur_p2])\n",
        "\n",
        "cur = Concatenate()([cur1, main_input])\n",
        "cur = Bidirectional(GRU(4, return_sequences=True))(cur)\n",
        "\n",
        "d = Dense(4, activation='relu') (cur)\n",
        "d = TimeDistributed(Dense(1, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1))) (d)\n",
        "\n",
        "d = Flatten()(d)\n",
        "\n",
        "main_output = d\n",
        "model = Model(main_input, main_output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='mse', metrics=['mse', 'accuracy'])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFBPmXEm8D1G",
        "outputId": "73d28372-f610-4064-cc03-b85d536b260d"
      },
      "source": [
        "len(trainX[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEL5zPTtE7Fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "bafd2f1d-4cd7-482f-d5bf-357827db6321"
      },
      "source": [
        "history = model.fit(trainX, trainY, \n",
        "                              epochs=10, batch_size=BATCH_SIZE, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2740 - mse: 0.2539 - accuracy: 0.0000e+00 - val_loss: 0.2557 - val_mse: 0.2502 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 171s 24ms/step - loss: 0.2560 - mse: 0.2520 - accuracy: 0.0000e+00 - val_loss: 0.2542 - val_mse: 0.2514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 175s 25ms/step - loss: 0.2540 - mse: 0.2514 - accuracy: 0.0000e+00 - val_loss: 0.2563 - val_mse: 0.2537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2529 - mse: 0.2508 - accuracy: 0.0000e+00 - val_loss: 0.2550 - val_mse: 0.2528 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2528 - mse: 0.2510 - accuracy: 0.0000e+00 - val_loss: 0.2555 - val_mse: 0.2536 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "7000/7000 [==============================] - 170s 24ms/step - loss: 0.2529 - mse: 0.2514 - accuracy: 0.0000e+00 - val_loss: 0.2551 - val_mse: 0.2534 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "7000/7000 [==============================] - 171s 24ms/step - loss: 0.2525 - mse: 0.2511 - accuracy: 0.0000e+00 - val_loss: 0.2534 - val_mse: 0.2522 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "5230/7000 [=====================>........] - ETA: 41s - loss: 0.2526 - mse: 0.2512 - accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-591bce46bbc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJI6ze-T-NR5"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz7xoJpw-Wld"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e1ZxgOO-ZMN"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4o9nmJ-bTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "b99b2420-0d09-4ced-cfa2-e1ac45a28e5a"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = Input(shape=(100,4))\n",
        "embedding_layer = TokenAndPositionEmbedding(100, 4, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a67acc1f7b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtransformer_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-8-0ee9fb568205>:14 call  *\n        attn_output = self.att(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:926 __call__  **\n        input_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1137 _functional_construction_call\n        '(layer: ' + self.name + ').')\n\n    ValueError: A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: multi_head_self_attention_2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_OhRdVMFneJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "bab3a2b7-bdd0-4fdb-ec3f-6932a3b2948d"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e3bbca2ec601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n\u001b[0m\u001b[1;32m      3\u001b[0m     (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLggnVbz-QBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "feec7351-cd2f-450e-a766-e7d8e86bbf35"
      },
      "source": [
        "d_model = 512\n",
        "dff=2048\n",
        "maximum_position_encoding = 10000\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "\n",
        "scaling_factor = tf.keras.backend.constant(np.sqrt(d_model), shape = (1,1,1))\n",
        "\n",
        "\n",
        "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "# Encoder ##################################\n",
        "input = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "x = tf.keras.layers.Embedding(input_vocab_size, d_model)(input) #, mask_zero=True\n",
        "\n",
        "## positional encoding\n",
        "x = tf.keras.layers.Multiply()([x,scaling_factor])\n",
        "pos = positional_encoding(maximum_position_encoding, d_model)\n",
        "x = tf.keras.layers.Add()([x, pos[: , :tf.shape(x)[1], :]] )\n",
        "\n",
        "## self-attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(x)\n",
        "key = tf.keras.layers.Dense(d_model)(x)\n",
        "attention = tf.keras.layers.Attention()([query, value, key])                   # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## Feed Forward\n",
        "dense = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "dense = tf.keras.layers.Dense(d_model)(dense)\n",
        "x = tf.keras.layers.Add()([x , dense])                                          # residual connection\n",
        "encoder = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "# Decoder ##################################\n",
        "target = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "x = tf.keras.layers.Embedding(target_vocab_size, d_model )(target) # , mask_zero=True\n",
        "\n",
        "## positional encoding\n",
        "x = tf.keras.layers.Multiply()([x,scaling_factor])\n",
        "pos = positional_encoding(maximum_position_encoding, d_model)\n",
        "x = tf.keras.layers.Add()([x, pos[: , :tf.shape(x)[1], :] ])\n",
        "\n",
        "## self-attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(x)\n",
        "key = tf.keras.layers.Dense(d_model)(x)\n",
        "attention = tf.keras.layers.Attention(causal = True)([query, value, key])       # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])                                      # residual connection\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## encoder-decoder attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(encoder)\n",
        "key = tf.keras.layers.Dense(d_model)(encoder)\n",
        "attention = tf.keras.layers.Attention()([query, value, key])                    # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])                                      # residual connection\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## Feed Forward\n",
        "dense = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "dense = tf.keras.layers.Dense(d_model)(dense)\n",
        "x = tf.keras.layers.Add()([x , dense])                                          # residual connection\n",
        "decoder = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "######################################################\n",
        "\n",
        "x = tf.keras.layers.Dense(target_vocab_size)(decoder)\n",
        "\n",
        "base_model = tf.keras.models.Model(inputs=[input,target], outputs=x)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-22a3b85dd0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmaximum_position_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_pt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer_pt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYvKr6ocGIm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c02b97-5d1d-483b-8941-cb3541c479c4"
      },
      "source": [
        "!pip install -U transformers-keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers-keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d0/6831dd9a37863fde38772fbdd9b06287f89d1213c68d5d8a1c0f21f365c8/transformers_keras-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jieba in /usr/local/lib/python3.6/dist-packages (from transformers-keras) (0.42.1)\n",
            "Installing collected packages: transformers-keras\n",
            "Successfully installed transformers-keras-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s7eCCiMG6AA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "4f258001-35e0-48aa-d310-db19cccab737"
      },
      "source": [
        "df = pd.DataFrame({'x': trainX.flatten(), 'y': trainY.flatten()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9bb82c3ae101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2juk1YGTGX"
      },
      "source": [
        "from transformers_keras import BertTFRecordDatasetBuilder\n",
        "\n",
        "builder = BertTFRecordDatasetBuilder(max_sequence_length=128, record_option='GZIP')\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='acc')\n",
        "model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
        "model(model.dummy_inputs())\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_dataset, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP0uuUxFH8VT"
      },
      "source": [
        "class Transformer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 src_vocab_size=-1,\n",
        "                 tgt_vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "        assert src_vocab_size > 0, \"src_vocab_size must greater than 0.\"\n",
        "        assert tgt_vocab_size > 0, \"tgt_vocab_size must greater than 0.\"\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoder_layers = num_encoder_layers\n",
        "        self.num_decoder_layers = num_decoder_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.encoder = TransformerEncoder(\n",
        "            src_vocab_size, max_positions, hidden_size,\n",
        "            num_layers=num_encoder_layers, dropout_rate=dropout_rate, epsilon=epsilon)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            tgt_vocab_size, max_positions, hidden_size,\n",
        "            num_layers=num_encoder_layers, dropout_rate=dropout_rate, epsilon=epsilon)\n",
        "        self.dense = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x_ids, y_ids = inputs\n",
        "\n",
        "        def _create_padding_mask(x):\n",
        "            mask = tf.cast(tf.equal(0, x), dtype=tf.float32)\n",
        "            mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
        "            return mask\n",
        "\n",
        "        def _create_look_ahead_mask(size):\n",
        "            mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "            return mask\n",
        "\n",
        "        def _create_masks(x, y):\n",
        "            _enc_padding_mask = _create_padding_mask(x)\n",
        "            _dec_padding_mask = _create_padding_mask(x)\n",
        "            _look_ahead_mask = _create_look_ahead_mask(tf.shape(y)[1])\n",
        "            _target_padding_mask = _create_padding_mask(y)\n",
        "            combined = tf.maximum(_look_ahead_mask, _target_padding_mask)\n",
        "            return _enc_padding_mask, combined, _dec_padding_mask\n",
        "\n",
        "        enc_padding_mask, dec_look_ahead_mask, dec_padding_mask = _create_masks(x_ids, y_ids)\n",
        "\n",
        "        enc_outputs, enc_attns = self.encoder(inputs=(x_ids, enc_padding_mask))\n",
        "\n",
        "        dec_outputs, dec_attns_0, dec_attns_1 = self.decoder(\n",
        "            inputs=(y_ids, enc_outputs, dec_look_ahead_mask, dec_padding_mask))\n",
        "\n",
        "        logits = self.dense(dec_outputs)\n",
        "        return logits, enc_attns, dec_attns_0, dec_attns_1\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"src_vocab_size\": self.src_vocab_size,\n",
        "            \"tgt_vocab_size\": self.tgt_vocab_size,\n",
        "            \"max_positions\": self.max_positions,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"num_encoder_layers\": self.num_encoder_layers,\n",
        "            \"num_decoder_layers\": self.num_decoder_layers,\n",
        "            \"num_attention_heads\": self.num_attention_heads,\n",
        "            \"ffn_size\": self.ffn_size,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"epsilon\": self.epsilon,\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kA5uWOAIX5v"
      },
      "source": [
        "\n",
        "class TransformerEmbedding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, vocab_size=1, max_positions=512, embedding_size=512, dropout_rate=0.2, **kwargs):\n",
        "        super(TransformerEmbedding, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.embedding_size = embedding_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.token_embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_size)\n",
        "        self.positional_encoding = PositionalEncoding(self.max_positions, self.embedding_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids = inputs\n",
        "        token_embeddings = self.token_embedding(token_ids)\n",
        "        position_embeddings = self.positional_encoding(token_ids)\n",
        "        embedding = token_embeddings + position_embeddings\n",
        "        embedding = self.dropout(embedding, training=training)\n",
        "        return embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        conf = {\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'embedding_size': self.embedding_size,\n",
        "            'dropout_rate': self.dropout_rate\n",
        "        }\n",
        "        p = super(TransformerEmbedding, self).get_config()\n",
        "        return dict(list(p.items()) + list(conf.items()))\n",
        "\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.embedding = TransformerEmbedding(vocab_size, max_positions, hidden_size, dropout_rate)\n",
        "        self.encoders = [\n",
        "            EncoderLayer(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                ffn_size=ffn_size,\n",
        "                dropout_rate=dropout_rate,\n",
        "                epsilon=epsilon,\n",
        "                name='EncoderLayer{}'.format(i)\n",
        "            ) for i in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids, mask = inputs\n",
        "        embeddings = self.embedding(inputs=token_ids)\n",
        "\n",
        "        attn_weights = []\n",
        "        outputs = embeddings\n",
        "        for i in range(self.num_layers):\n",
        "            encoder = self.encoders[i]\n",
        "            outputs, weights = encoder(inputs=(outputs, outputs, outputs, mask))\n",
        "            attn_weights.append(weights)\n",
        "\n",
        "        return outputs, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_layers': self.num_layers,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        p = super().get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.embedding = TransformerEmbedding(vocab_size, max_positions, hidden_size, dropout_rate)\n",
        "        self.decoders = [\n",
        "            DecoderLayer(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                ffn_size=ffn_size,\n",
        "                dropout_rate=dropout_rate,\n",
        "                epsilon=epsilon,\n",
        "                name='DecoderLayer{}'.format(i)\n",
        "            ) for i in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids, enc_outputs, look_ahead_mask, padding_mask = inputs\n",
        "        embeddings = self.embedding(token_ids)\n",
        "\n",
        "        self_attn_weights, context_attn_weights = [], []\n",
        "        outputs = embeddings\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            decoder = self.decoders[i]\n",
        "            outputs, self_attn, context_attn = decoder(inputs=(outputs, enc_outputs, look_ahead_mask, padding_mask))\n",
        "            self_attn_weights.append(self_attn)\n",
        "            context_attn_weights.append(context_attn)\n",
        "\n",
        "        return outputs, self_attn_weights, context_attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_layers': self.num_layers,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        p = super(TransformerDecoder, self).get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHhwHOQkIhyw"
      },
      "source": [
        "class TransformerLearningRate(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"Learning rate schedule for Transformer.\"\"\"\n",
        "\n",
        "    def __init__(self, depth, warmup_steps=4000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            depth: Python integer, the model's hidden size\n",
        "            warmup_steps: Python integer, steps to warmup learning rate\n",
        "        \"\"\"\n",
        "        self.depth = depth\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(tf.cast(self.depth, tf.float32)) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'depth': self.depth,\n",
        "            'warmup_steps': self.warmup_steps\n",
        "        }\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZjRzg4bJAUI"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, max_positions=512, embedding_size=512, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.max_positions = max_positions\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        def _initializer(shape, dtype=tf.float32):\n",
        "            pos = np.arange(self.max_positions)[:, tf.newaxis]\n",
        "            d = np.arange(self.embedding_size)[tf.newaxis, :]\n",
        "            rads = 1 / np.power(10000, (2 * (d // 2)) / np.float32(self.embedding_size))\n",
        "            rads = pos * rads\n",
        "\n",
        "            rads[:, 0::2] = np.sin(rads[:, 0::2])\n",
        "            rads[:, 1::2] = np.cos(rads[:, 1::2])\n",
        "\n",
        "            rads = tf.cast(rads, dtype=dtype)\n",
        "            rads = tf.reshape(rads, shape=shape)\n",
        "            return rads\n",
        "\n",
        "        self.position_embedding = self.add_weight(\n",
        "            name='position_embedding',\n",
        "            shape=(self.max_positions, self.embedding_size),\n",
        "            dtype=tf.float32,\n",
        "            initializer=_initializer,\n",
        "            trainable=False)\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids = inputs\n",
        "        pos_embedding = self.position_embedding[tf.newaxis, :]\n",
        "        embedding = pos_embedding[:, :tf.shape(token_ids)[1], :]\n",
        "        return embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'max_positions': self.max_positions,\n",
        "            'embedding_size': self.embedding_size\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2-BebvSJNHM"
      },
      "source": [
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, ffn_size=2048, dropout_rate=0.2, epsilon=1e-6, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(self.hidden_size, self.ffn_size)\n",
        "        self.ffn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.ffn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        attn, attn_weights = self.attention(inputs=(query, key, value, mask))\n",
        "        attn = self.attn_dropout(attn, training=training)\n",
        "        attn = self.attn_layer_norm(query + attn)\n",
        "\n",
        "        ffn = self.ffn(attn)\n",
        "        ffn = self.ffn_dropout(ffn, training=training)\n",
        "        ffn = self.ffn_layer_norm(ffn + attn)\n",
        "\n",
        "        return ffn, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, ffn_size=2048, dropout_rate=0.2, epsilon=1e-6, **kwargs):\n",
        "        super(DecoderLayer, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.self_attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.self_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.context_attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.context_attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.context_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(self.hidden_size, self.ffn_size)\n",
        "        self.ffn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.ffn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x, enc_outputs, look_ahead_mask, padding_mask = inputs\n",
        "\n",
        "        attn1, attn1_weights = self.self_attention(inputs=(x, x, x, look_ahead_mask))\n",
        "        attn1 = self.self_attn_dropout(attn1, training=training)\n",
        "        output1 = self.self_attn_layer_norm(attn1 + x)\n",
        "\n",
        "        attn2, attn2_weights = self.context_attention(inputs=(output1, enc_outputs, enc_outputs, padding_mask))\n",
        "        attn2 = self.context_attn_dropout(attn2, training=training)\n",
        "        output2 = self.context_attn_layer_norm(attn2 + output1)\n",
        "\n",
        "        ffn = self.ffn(output2)\n",
        "        ffn = self.ffn_dropout(ffn, training=training)\n",
        "        ffn = self.ffn_layer_norm(ffn + attn2)\n",
        "\n",
        "        return ffn, attn1_weights, attn2_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        base = super(DecoderLayer, self).get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMTQedF8JhhI"
      },
      "source": [
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        assert self.hidden_size % self.num_attention_heads == 0\n",
        "\n",
        "        self.query_weight = tf.keras.layers.Dense(self.hidden_size, name='query')\n",
        "        self.key_weight = tf.keras.layers.Dense(self.hidden_size, name='key')\n",
        "        self.value_weight = tf.keras.layers.Dense(self.hidden_size, name='value')\n",
        "\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(self.hidden_size, name='dense')\n",
        "\n",
        "    def _split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.hidden_size // self.num_attention_heads))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        query = self._split_heads(self.query_weight(query), batch_size)\n",
        "        key = self._split_heads(self.key_weight(key), batch_size)\n",
        "        value = self._split_heads(self.value_weight(value), batch_size)\n",
        "\n",
        "        context, attn_weights = self.attention(inputs=(query, key, value, mask))\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])\n",
        "        context = tf.reshape(context, [batch_size, -1, self.hidden_size])\n",
        "        output = self.dense(context)\n",
        "        return output, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Csj6knJpwd"
      },
      "source": [
        "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        query = tf.cast(query, dtype=self.dtype)\n",
        "        key = tf.cast(key, dtype=self.dtype)\n",
        "        value = tf.cast(value, dtype=self.dtype)\n",
        "\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dk = tf.cast(tf.shape(query)[-1], tf.float32)\n",
        "        score = score / tf.math.sqrt(dk)\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=self.dtype)\n",
        "            score += mask * -10000.0\n",
        "        attn_weights = tf.nn.softmax(score, axis=-1)\n",
        "        context = tf.matmul(attn_weights, value)\n",
        "        return context, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "\n",
        "class PointWiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, ffn_size=2048, **kwargs):\n",
        "        super(PointWiseFeedForwardNetwork, self).__init__(**kwargs)\n",
        "        self.ffn_size = ffn_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dense1 = tf.keras.layers.Dense(self.ffn_size, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(self.hidden_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        outputs = self.dense2(self.dense1(inputs))\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'hidden_size': self.hidden_size,\n",
        "        }\n",
        "        p = super(PointWiseFeedForwardNetwork, self).get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBHA83CH-BH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "05552164-58c8-4203-e925-06d5bb200339"
      },
      "source": [
        "x = tf.keras.layers.Input((None, 100, 4), dtype=tf.int32, name='x')\n",
        "y = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='y')\n",
        "model = Transformer(src_vocab_size=4,\n",
        "                 tgt_vocab_size=4)\n",
        "inputs=Input(shape=(100,4))\n",
        "logits, _, _, _ = model(inputs=inputs)\n",
        "probs = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.nn.softmax(x), name='probs')(logits)\n",
        "\n",
        "model = tf.keras.Model(inputs=[x, y], outputs=[probs])\n",
        "\n",
        "lr = 0.1 #TransformerLearningRate(config.get('hidden_size', 512))\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(name='loss', from_logits=False),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='acc')],\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    <ipython-input-29-c8c5ccfc8e75>:37 call  *\n        x_ids, y_ids = inputs\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:479 _disallow_in_graph_mode\n        \" this function with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ccde5946f3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                  tgt_vocab_size=4)\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m probs = tf.keras.layers.Lambda(\n\u001b[1;32m      8\u001b[0m     lambda x: tf.nn.softmax(x), name='probs')(logits)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                             \u001b[0;34m'dynamic. Pass `dynamic=True` to the class '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                             \u001b[0;34m'constructor.\\nEncountered error:\\n\"\"\"\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                             '\\n\"\"\"')\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m           \u001b[0;31m# We will use static shape inference to return symbolic tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\nEncountered error:\n\"\"\"\nin user code:\n\n    <ipython-input-29-c8c5ccfc8e75>:37 call  *\n        x_ids, y_ids = inputs\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:479 _disallow_in_graph_mode\n        \" this function with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n\n\"\"\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ125GE0KTYD"
      },
      "source": [
        "epochs=10,\n",
        "ckpt_steps=2000,\n",
        "export_steps=5000,\n",
        "callbacks=None,\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuTWJ852LCok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "aa91de12-63f4-4395-f144-ee68fe67a4e2"
      },
      "source": [
        "history = model.fit(trainX, trainY, \n",
        "                              epochs=10, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"x_10:0\", shape=(None, 100), dtype=int32), but it was called on an input with incompatible shape (None, 100, 4).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-21a093d94e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"probs/Softmax_2:0\", shape=(None, 4, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN_CQOS9KltM"
      },
      "source": [
        "        history = self.model.fit(\n",
        "            train_dataset,\n",
        "            validation_data=valid_dataset,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}