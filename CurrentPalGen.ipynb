{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CurrentPalGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlekseiShevkoplias/Intragenic/blob/rubbish/CurrentPalGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km42r3SmeE_p"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate, Lambda, Add, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igrWDv1c2ano"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM, Input\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "COMPLEMENT = {\n",
        "    'A': 'T',\n",
        "    'G': 'C',\n",
        "    'T': 'A', \n",
        "    'C': 'G'\n",
        "}\n",
        "\n",
        "NUC = ['A', 'T', 'G', 'C']\n",
        "\n",
        "TOKENS = {\n",
        "    'A': [1, 0, 0, 0],\n",
        "    'G': [0, 1, 0, 0],\n",
        "    'T': [0, 0, 1, 0], \n",
        "    'C': [0, 0, 0, 1], \n",
        "    'X': [0, 0, 0, 0]\n",
        "}\n",
        "\n",
        "def tokenize(seq):\n",
        "    tokenized = []\n",
        "    for nuc in seq:\n",
        "        tokenized.append(TOKENS[nuc])\n",
        "    return tokenized\n",
        "\n",
        "def generate_palindromes(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA palindromes.\n",
        "    n: the number of palindromes to be generated\n",
        "    \"\"\"\n",
        "    palindromes = []\n",
        "    for j in range(n):\n",
        "  \n",
        "        pal_length = random.randint(2, 10)\n",
        "\n",
        "        palindrome = ''\n",
        "        for i in range(50 - pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "        for i in range(pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "        for i in range(pal_length - 1, -1, -1):\n",
        "            palindrome += COMPLEMENT[palindrome[i]]\n",
        "        \n",
        "        for i in range(50 - pal_length):\n",
        "            palindrome += random.choice(NUC)\n",
        "\n",
        "\n",
        "        palindromes.append(palindrome)\n",
        "\n",
        "    return palindromes\n",
        "\n",
        "\n",
        "def generate_sd(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA with inserted SD.\n",
        "    n: the number of palindromes to be generated.\n",
        "    \"\"\"\n",
        "    sds = []\n",
        "    for i in range(n):\n",
        "        sd = ''\n",
        "        for i in range(47):\n",
        "            sd += random.choice(NUC)\n",
        "        sd += 'AGGAGG'\n",
        "        for i in range(47):\n",
        "            sd += random.choice(NUC)\n",
        "\n",
        "        sds.append(sd)\n",
        "\n",
        "    return sds\n",
        "\n",
        "def test_sd(seq):\n",
        "    if 'AGGAGG' in seq[47:54]:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def test_palindrome(seq):\n",
        "    \"\"\"\n",
        "    Tests whether the seq is a DNA palindrome or not.\n",
        "    seq: A str object with the DNA sequence\n",
        "    return: True if seq is a palindrome and False if not\n",
        "    \"\"\"\n",
        "    assert isinstance(seq, str)\n",
        "    complementary = ''\n",
        "    for i in range(len(seq)//2 - 1, -1, -1):\n",
        "        complementary += COMPLEMENT[seq[i]]\n",
        "    return complementary == seq[len(seq)//2:]\n",
        "\n",
        "def generate_negatives(n):\n",
        "    \"\"\"\n",
        "    Generates n DNA non-palindromes.\n",
        "    n: the number of negatives to be generated\n",
        "    \"\"\"\n",
        "    negs = []\n",
        "    for j in range(n):\n",
        "        is_palindrome = True\n",
        "        neg_length = random.randint(2, 10) * 2\n",
        "        preneg = ''\n",
        "\n",
        "        for i in range(50 - neg_length//2):\n",
        "            preneg += random.choice(NUC)\n",
        "\n",
        "        while is_palindrome:\n",
        "            \n",
        "\n",
        "            neg = ''\n",
        "\n",
        "            for i in range(neg_length):\n",
        "                neg += random.choice(NUC)\n",
        "\n",
        "            is_palindrome = test_palindrome(neg) or test_sd(neg)\n",
        "        neg = preneg + neg\n",
        "\n",
        "        for i in range(50 - neg_length//2):\n",
        "            neg += random.choice(NUC)\n",
        "\n",
        "        negs.append(neg)\n",
        "\n",
        "    return negs\n",
        "\n",
        "def generate_rubbish(n):\n",
        "    \"\"\"\n",
        "    Negative with X in the middle\n",
        "    \"\"\"\n",
        "    rubbishes = []\n",
        "    for i in range(n):\n",
        "        rubbish = ''\n",
        "        for i in range(50):\n",
        "            rubbish += random.choice(NUC)\n",
        "        rubbish += 'X'\n",
        "        for i in range(49):\n",
        "            rubbish += random.choice(NUC)\n",
        "        rubbishes.append(rubbish)\n",
        "\n",
        "    return rubbishes\n",
        "\n",
        "class PalNegDataset:\n",
        "    def __init__(self, n_pal, n_sd, n_neg, n_rubbish = 0):\n",
        "        \n",
        "        self.n_pal = n_pal\n",
        "        self.n_sd = n_sd\n",
        "        self.n_neg = n_neg\n",
        "        self.n_rubbish = n_rubbish\n",
        "\n",
        "        self.palindromes = generate_palindromes(n_pal)\n",
        "        self.sds = generate_sd(n_sd)\n",
        "        self.negatives = generate_negatives(n_neg)\n",
        "        self.data = self.generate_data()\n",
        "        self.sequences = self.palindromes + self.sds + self.negatives\n",
        "\n",
        "        random.shuffle(self.sequences)\n",
        "        self.status = K.constant([self.data[key] for key in self.sequences])\n",
        "        self.tokenized_seq = np.array([tokenize(seq) for seq in self.sequences])\n",
        "        self.middles = np.array([tokenize(seq[50]) for seq in self.sequences])\n",
        "\n",
        "        # different stuff (likely will be deleted later)\n",
        "        self.palmiddles = np.array([tokenize(seq[50]) for seq in self.palindromes])\n",
        "        self.palmiddles = self.palmiddles.reshape([self.palmiddles.shape[0], 4])\n",
        "\n",
        "        if self.n_rubbish > 0:\n",
        "            self.rubbish = generate_rubbish(n_rubbish)\n",
        "            self.rubbish_middles = np.array([tokenize(seq[50]) for seq in self.rubbish])\n",
        "            self.rubbish_middles = self.rubbish_middles.reshape([self.rubbish_middles.shape[0], 4])\n",
        "            self.tokenized_rubbish = np.array([tokenize(seq) for seq in self.rubbish])\n",
        "            self.tokenized_rubbish = np.array([np.append(np.append(seq[:50], np.array([[0, 0, 0, 0]]), axis=0), seq[51:], axis = 0) for seq in self.tokenized_rubbish])\n",
        "\n",
        "        self.tokenized_pals = np.array([tokenize(seq) for seq in self.palindromes])\n",
        "        self.tokenized_pals = np.array([np.append(np.append(seq[:50], np.array([[0, 0, 0, 0]]), axis=0), seq[51:], axis = 0) for seq in self.tokenized_pals])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_pal + self.n_neg\n",
        "\n",
        "    def generate_data(self):\n",
        "        data = {}\n",
        "        for pal in self.palindromes:\n",
        "            data[pal] = 1\n",
        "        for sd in self.sds:\n",
        "            data[sd] = 1\n",
        "        for neg in self.negatives:\n",
        "            data[neg] = 0        \n",
        "        return data\n",
        "    \n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2cgh6zNDWnw"
      },
      "source": [
        "t = PalNegDataset(5000, 0, 5000, n_rubbish=5000)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu4QLEOandUn",
        "outputId": "56b61689-941c-4978-f709-66722eb91d10"
      },
      "source": [
        "t.status[100:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7yic8q-zlu"
      },
      "source": [
        "trainX = t.tokenized_seq[:7000]\n",
        "testX = t.tokenized_seq[7000:9000]\n",
        "valX = t.tokenized_seq[9000:]\n",
        "trainY = t.status[:7000]\n",
        "testY = t.status[7000:9000]\n",
        "valY = t.status[9000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsJ4o5r6f4V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca44833-a598-4e67-9591-a69bc40b5ced"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGqfTpdBDYxO"
      },
      "source": [
        "# палиндромы для проверки предсказания нуклеотида\n",
        "frX_train = t.tokenized_pals[:4000] + t.tokenized_rubbish[:4000] \n",
        "frY_train = t.palmiddles[:4000] + t.rubbish_middles[:4000]\n",
        "\n",
        "frX_val = t.tokenized_pals[4000:] + t.tokenized_rubbish[4000:] \n",
        "frY_val = t.palmiddles[4000:]+ t.rubbish_middles[4000:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j36VSVtzDluI",
        "outputId": "be5ff717-41a2-4c8b-a082-e360f7cb75ca"
      },
      "source": [
        "frX_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tgbwMVvY5frY",
        "outputId": "1a01e189-37fc-43a9-8e45-57671e4780d6"
      },
      "source": [
        "# From find_repeat\n",
        "ms = []\n",
        "\n",
        "def run_model():\n",
        "    inp = Input((100, 4))\n",
        "    cur_p = Conv1D(filters=32, kernel_size=10, padding='SAME')(inp)\n",
        "    cur_p2 = Conv1D(filters=32, kernel_size=10, padding='SAME')(inp)\n",
        "    cur = Attention()([cur_p, inp, cur_p2])\n",
        "    cur = Flatten()(cur)\n",
        "    cur = Dense(4, activation='softmax')(cur)\n",
        "    # cur = Dense(1, activation='softmax')(cur)\n",
        "    model = Model(inp, cur)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', 'categorical_crossentropy'])    \n",
        "    model.summary()\n",
        "\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', patience=8, restore_best_weights=True)\n",
        "    callbacks = []\n",
        "    callbacks.append(es)\n",
        "\n",
        "    history = model.fit(frX_train, frY_train, epochs=100,  batch_size=32, \n",
        "                         validation_data=(frX_val, frY_val), \n",
        "                         callbacks=[], verbose=1)\n",
        "\n",
        "    def show(history, acc_on=True):\n",
        "        for k, v in history.history.items():\n",
        "            if int('acc' not in k) + int(acc_on) == 1:\n",
        "                plt.plot(v, label=k)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    show(history, True)\n",
        "    show(history, False)\n",
        "\n",
        "    ms.append(model)\n",
        "    # loss, test_acc, test_cat = model.evaluate(test_q, test_ans, verbose=1)\n",
        "    # return test_acc\n",
        "\n",
        "accs = [run_model() for _ in range(1)]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100, 4)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 100, 32)      1312        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 100, 32)      1312        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (Attention)           (None, 100, 4)       0           conv1d[0][0]                     \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 400)          0           attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            1604        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,228\n",
            "Trainable params: 4,228\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 3s 15ms/step - loss: 1.4232 - accuracy: 0.2518 - categorical_crossentropy: 1.4232 - val_loss: 1.4213 - val_accuracy: 0.2490 - val_categorical_crossentropy: 1.4213\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3941 - accuracy: 0.2732 - categorical_crossentropy: 1.3941 - val_loss: 1.3860 - val_accuracy: 0.2580 - val_categorical_crossentropy: 1.3860\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3712 - accuracy: 0.3097 - categorical_crossentropy: 1.3712 - val_loss: 1.3887 - val_accuracy: 0.2730 - val_categorical_crossentropy: 1.3887\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3628 - accuracy: 0.3125 - categorical_crossentropy: 1.3628 - val_loss: 1.3964 - val_accuracy: 0.2780 - val_categorical_crossentropy: 1.3964\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.3428 - accuracy: 0.3459 - categorical_crossentropy: 1.3428 - val_loss: 1.4119 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.4119\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.3129 - accuracy: 0.3824 - categorical_crossentropy: 1.3129 - val_loss: 1.3946 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.3946\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2876 - accuracy: 0.4100 - categorical_crossentropy: 1.2876 - val_loss: 1.4009 - val_accuracy: 0.2880 - val_categorical_crossentropy: 1.4009\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2619 - accuracy: 0.4214 - categorical_crossentropy: 1.2619 - val_loss: 1.4060 - val_accuracy: 0.2850 - val_categorical_crossentropy: 1.4060\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.2308 - accuracy: 0.4573 - categorical_crossentropy: 1.2308 - val_loss: 1.4325 - val_accuracy: 0.2980 - val_categorical_crossentropy: 1.4325\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.2318 - accuracy: 0.4476 - categorical_crossentropy: 1.2318 - val_loss: 1.4537 - val_accuracy: 0.2930 - val_categorical_crossentropy: 1.4537\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1910 - accuracy: 0.4735 - categorical_crossentropy: 1.1910 - val_loss: 1.4594 - val_accuracy: 0.2970 - val_categorical_crossentropy: 1.4594\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1.1896 - accuracy: 0.4708 - categorical_crossentropy: 1.1896 - val_loss: 1.4537 - val_accuracy: 0.2840 - val_categorical_crossentropy: 1.4537\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1465 - accuracy: 0.5193 - categorical_crossentropy: 1.1465 - val_loss: 1.4802 - val_accuracy: 0.2800 - val_categorical_crossentropy: 1.4802\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1236 - accuracy: 0.5210 - categorical_crossentropy: 1.1236 - val_loss: 1.4988 - val_accuracy: 0.2750 - val_categorical_crossentropy: 1.4988\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.1104 - accuracy: 0.5277 - categorical_crossentropy: 1.1104 - val_loss: 1.4990 - val_accuracy: 0.2800 - val_categorical_crossentropy: 1.4990\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0967 - accuracy: 0.5278 - categorical_crossentropy: 1.0967 - val_loss: 1.5186 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.5186\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0797 - accuracy: 0.5431 - categorical_crossentropy: 1.0797 - val_loss: 1.5375 - val_accuracy: 0.2970 - val_categorical_crossentropy: 1.5375\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0537 - accuracy: 0.5694 - categorical_crossentropy: 1.0537 - val_loss: 1.5593 - val_accuracy: 0.2870 - val_categorical_crossentropy: 1.5593\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0475 - accuracy: 0.5681 - categorical_crossentropy: 1.0475 - val_loss: 1.5909 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.5909\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0273 - accuracy: 0.5822 - categorical_crossentropy: 1.0273 - val_loss: 1.6039 - val_accuracy: 0.2790 - val_categorical_crossentropy: 1.6039\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 1.0064 - accuracy: 0.5899 - categorical_crossentropy: 1.0064 - val_loss: 1.6151 - val_accuracy: 0.2870 - val_categorical_crossentropy: 1.6151\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9996 - accuracy: 0.5912 - categorical_crossentropy: 0.9996 - val_loss: 1.6433 - val_accuracy: 0.2730 - val_categorical_crossentropy: 1.6433\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9973 - accuracy: 0.5926 - categorical_crossentropy: 0.9973 - val_loss: 1.6508 - val_accuracy: 0.2790 - val_categorical_crossentropy: 1.6508\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9745 - accuracy: 0.6003 - categorical_crossentropy: 0.9745 - val_loss: 1.6725 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.6725\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9592 - accuracy: 0.6226 - categorical_crossentropy: 0.9592 - val_loss: 1.7013 - val_accuracy: 0.2920 - val_categorical_crossentropy: 1.7013\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9414 - accuracy: 0.6240 - categorical_crossentropy: 0.9414 - val_loss: 1.7279 - val_accuracy: 0.2800 - val_categorical_crossentropy: 1.7279\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9226 - accuracy: 0.6347 - categorical_crossentropy: 0.9226 - val_loss: 1.7634 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.7634\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9194 - accuracy: 0.6310 - categorical_crossentropy: 0.9194 - val_loss: 1.7677 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.7677\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8961 - accuracy: 0.6389 - categorical_crossentropy: 0.8961 - val_loss: 1.7785 - val_accuracy: 0.2870 - val_categorical_crossentropy: 1.7785\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8965 - accuracy: 0.6469 - categorical_crossentropy: 0.8965 - val_loss: 1.8068 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.8068\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8858 - accuracy: 0.6351 - categorical_crossentropy: 0.8858 - val_loss: 1.8081 - val_accuracy: 0.2920 - val_categorical_crossentropy: 1.8081\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.9013 - accuracy: 0.6359 - categorical_crossentropy: 0.9013 - val_loss: 1.8268 - val_accuracy: 0.2760 - val_categorical_crossentropy: 1.8268\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8803 - accuracy: 0.6479 - categorical_crossentropy: 0.8803 - val_loss: 1.8473 - val_accuracy: 0.2840 - val_categorical_crossentropy: 1.8473\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8663 - accuracy: 0.6468 - categorical_crossentropy: 0.8663 - val_loss: 1.8823 - val_accuracy: 0.2880 - val_categorical_crossentropy: 1.8823\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8499 - accuracy: 0.6636 - categorical_crossentropy: 0.8499 - val_loss: 1.8956 - val_accuracy: 0.2930 - val_categorical_crossentropy: 1.8956\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8583 - accuracy: 0.6638 - categorical_crossentropy: 0.8583 - val_loss: 1.9191 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.9191\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8542 - accuracy: 0.6556 - categorical_crossentropy: 0.8542 - val_loss: 1.9198 - val_accuracy: 0.2840 - val_categorical_crossentropy: 1.9198\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8195 - accuracy: 0.6862 - categorical_crossentropy: 0.8195 - val_loss: 1.9402 - val_accuracy: 0.2850 - val_categorical_crossentropy: 1.9402\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8443 - accuracy: 0.6758 - categorical_crossentropy: 0.8443 - val_loss: 1.9560 - val_accuracy: 0.2820 - val_categorical_crossentropy: 1.9560\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.8281 - accuracy: 0.6761 - categorical_crossentropy: 0.8281 - val_loss: 1.9813 - val_accuracy: 0.2930 - val_categorical_crossentropy: 1.9813\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8222 - accuracy: 0.6784 - categorical_crossentropy: 0.8222 - val_loss: 1.9993 - val_accuracy: 0.2950 - val_categorical_crossentropy: 1.9993\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.8345 - accuracy: 0.6726 - categorical_crossentropy: 0.8345 - val_loss: 2.0341 - val_accuracy: 0.2830 - val_categorical_crossentropy: 2.0341\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7924 - accuracy: 0.6902 - categorical_crossentropy: 0.7924 - val_loss: 2.0204 - val_accuracy: 0.2850 - val_categorical_crossentropy: 2.0204\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7917 - accuracy: 0.6913 - categorical_crossentropy: 0.7917 - val_loss: 2.0433 - val_accuracy: 0.2940 - val_categorical_crossentropy: 2.0433\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7980 - accuracy: 0.6863 - categorical_crossentropy: 0.7980 - val_loss: 2.0570 - val_accuracy: 0.2920 - val_categorical_crossentropy: 2.0570\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7778 - accuracy: 0.7066 - categorical_crossentropy: 0.7778 - val_loss: 2.1026 - val_accuracy: 0.2940 - val_categorical_crossentropy: 2.1026\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7947 - accuracy: 0.6899 - categorical_crossentropy: 0.7947 - val_loss: 2.1177 - val_accuracy: 0.2850 - val_categorical_crossentropy: 2.1177\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7726 - accuracy: 0.7070 - categorical_crossentropy: 0.7726 - val_loss: 2.1242 - val_accuracy: 0.2870 - val_categorical_crossentropy: 2.1242\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7586 - accuracy: 0.7059 - categorical_crossentropy: 0.7586 - val_loss: 2.1591 - val_accuracy: 0.2820 - val_categorical_crossentropy: 2.1591\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7560 - accuracy: 0.7061 - categorical_crossentropy: 0.7560 - val_loss: 2.1672 - val_accuracy: 0.2840 - val_categorical_crossentropy: 2.1672\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7553 - accuracy: 0.7143 - categorical_crossentropy: 0.7553 - val_loss: 2.1853 - val_accuracy: 0.2890 - val_categorical_crossentropy: 2.1853\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7474 - accuracy: 0.7123 - categorical_crossentropy: 0.7474 - val_loss: 2.1850 - val_accuracy: 0.2850 - val_categorical_crossentropy: 2.1850\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7532 - accuracy: 0.7100 - categorical_crossentropy: 0.7532 - val_loss: 2.2198 - val_accuracy: 0.2810 - val_categorical_crossentropy: 2.2198\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7374 - accuracy: 0.7157 - categorical_crossentropy: 0.7374 - val_loss: 2.2476 - val_accuracy: 0.2830 - val_categorical_crossentropy: 2.2476\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7653 - accuracy: 0.7047 - categorical_crossentropy: 0.7653 - val_loss: 2.2761 - val_accuracy: 0.2840 - val_categorical_crossentropy: 2.2761\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7597 - accuracy: 0.6997 - categorical_crossentropy: 0.7597 - val_loss: 2.2732 - val_accuracy: 0.2830 - val_categorical_crossentropy: 2.2732\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 2s 15ms/step - loss: 0.7290 - accuracy: 0.7330 - categorical_crossentropy: 0.7290 - val_loss: 2.2772 - val_accuracy: 0.2780 - val_categorical_crossentropy: 2.2772\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7448 - accuracy: 0.7033 - categorical_crossentropy: 0.7448 - val_loss: 2.3077 - val_accuracy: 0.2800 - val_categorical_crossentropy: 2.3077\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7451 - accuracy: 0.7163 - categorical_crossentropy: 0.7451 - val_loss: 2.3281 - val_accuracy: 0.2820 - val_categorical_crossentropy: 2.3281\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7423 - accuracy: 0.7116 - categorical_crossentropy: 0.7423 - val_loss: 2.3360 - val_accuracy: 0.2800 - val_categorical_crossentropy: 2.3360\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7357 - accuracy: 0.7178 - categorical_crossentropy: 0.7357 - val_loss: 2.3664 - val_accuracy: 0.2820 - val_categorical_crossentropy: 2.3664\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7529 - accuracy: 0.7031 - categorical_crossentropy: 0.7529 - val_loss: 2.3825 - val_accuracy: 0.2760 - val_categorical_crossentropy: 2.3825\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7284 - accuracy: 0.7205 - categorical_crossentropy: 0.7284 - val_loss: 2.4000 - val_accuracy: 0.2910 - val_categorical_crossentropy: 2.4000\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7067 - accuracy: 0.7318 - categorical_crossentropy: 0.7067 - val_loss: 2.4028 - val_accuracy: 0.2770 - val_categorical_crossentropy: 2.4028\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7185 - accuracy: 0.7271 - categorical_crossentropy: 0.7185 - val_loss: 2.4076 - val_accuracy: 0.2760 - val_categorical_crossentropy: 2.4076\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.7110 - accuracy: 0.7357 - categorical_crossentropy: 0.7110 - val_loss: 2.4252 - val_accuracy: 0.2680 - val_categorical_crossentropy: 2.4252\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6869 - accuracy: 0.7409 - categorical_crossentropy: 0.6869 - val_loss: 2.4489 - val_accuracy: 0.2720 - val_categorical_crossentropy: 2.4489\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7094 - accuracy: 0.7273 - categorical_crossentropy: 0.7094 - val_loss: 2.4594 - val_accuracy: 0.2710 - val_categorical_crossentropy: 2.4594\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6969 - accuracy: 0.7343 - categorical_crossentropy: 0.6969 - val_loss: 2.4906 - val_accuracy: 0.2750 - val_categorical_crossentropy: 2.4906\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6844 - accuracy: 0.7398 - categorical_crossentropy: 0.6844 - val_loss: 2.4852 - val_accuracy: 0.2760 - val_categorical_crossentropy: 2.4852\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6948 - accuracy: 0.7290 - categorical_crossentropy: 0.6948 - val_loss: 2.5057 - val_accuracy: 0.2690 - val_categorical_crossentropy: 2.5057\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7039 - accuracy: 0.7300 - categorical_crossentropy: 0.7039 - val_loss: 2.5145 - val_accuracy: 0.2720 - val_categorical_crossentropy: 2.5145\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6901 - accuracy: 0.7375 - categorical_crossentropy: 0.6901 - val_loss: 2.5238 - val_accuracy: 0.2700 - val_categorical_crossentropy: 2.5238\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6807 - accuracy: 0.7426 - categorical_crossentropy: 0.6807 - val_loss: 2.5554 - val_accuracy: 0.2700 - val_categorical_crossentropy: 2.5554\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6831 - accuracy: 0.7319 - categorical_crossentropy: 0.6831 - val_loss: 2.5564 - val_accuracy: 0.2790 - val_categorical_crossentropy: 2.5564\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6617 - accuracy: 0.7435 - categorical_crossentropy: 0.6617 - val_loss: 2.5595 - val_accuracy: 0.2720 - val_categorical_crossentropy: 2.5595\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6716 - accuracy: 0.7386 - categorical_crossentropy: 0.6716 - val_loss: 2.5850 - val_accuracy: 0.2630 - val_categorical_crossentropy: 2.5850\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6710 - accuracy: 0.7473 - categorical_crossentropy: 0.6710 - val_loss: 2.5735 - val_accuracy: 0.2800 - val_categorical_crossentropy: 2.5735\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6744 - accuracy: 0.7393 - categorical_crossentropy: 0.6744 - val_loss: 2.6089 - val_accuracy: 0.2720 - val_categorical_crossentropy: 2.6089\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6539 - accuracy: 0.7552 - categorical_crossentropy: 0.6539 - val_loss: 2.6157 - val_accuracy: 0.2650 - val_categorical_crossentropy: 2.6157\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6563 - accuracy: 0.7448 - categorical_crossentropy: 0.6563 - val_loss: 2.6176 - val_accuracy: 0.2680 - val_categorical_crossentropy: 2.6176\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6539 - accuracy: 0.7535 - categorical_crossentropy: 0.6539 - val_loss: 2.6399 - val_accuracy: 0.2810 - val_categorical_crossentropy: 2.6399\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6590 - accuracy: 0.7602 - categorical_crossentropy: 0.6590 - val_loss: 2.6361 - val_accuracy: 0.2800 - val_categorical_crossentropy: 2.6361\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6287 - accuracy: 0.7692 - categorical_crossentropy: 0.6287 - val_loss: 2.6539 - val_accuracy: 0.2800 - val_categorical_crossentropy: 2.6539\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6565 - accuracy: 0.7459 - categorical_crossentropy: 0.6565 - val_loss: 2.6630 - val_accuracy: 0.2770 - val_categorical_crossentropy: 2.6630\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6526 - accuracy: 0.7532 - categorical_crossentropy: 0.6526 - val_loss: 2.6867 - val_accuracy: 0.2690 - val_categorical_crossentropy: 2.6867\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6252 - accuracy: 0.7724 - categorical_crossentropy: 0.6252 - val_loss: 2.6966 - val_accuracy: 0.2740 - val_categorical_crossentropy: 2.6966\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 2s 16ms/step - loss: 0.6323 - accuracy: 0.7564 - categorical_crossentropy: 0.6323 - val_loss: 2.7101 - val_accuracy: 0.2800 - val_categorical_crossentropy: 2.7101\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6330 - accuracy: 0.7634 - categorical_crossentropy: 0.6330 - val_loss: 2.7247 - val_accuracy: 0.2790 - val_categorical_crossentropy: 2.7247\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6391 - accuracy: 0.7579 - categorical_crossentropy: 0.6391 - val_loss: 2.7529 - val_accuracy: 0.2710 - val_categorical_crossentropy: 2.7529\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6466 - accuracy: 0.7617 - categorical_crossentropy: 0.6466 - val_loss: 2.7584 - val_accuracy: 0.2760 - val_categorical_crossentropy: 2.7584\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6325 - accuracy: 0.7662 - categorical_crossentropy: 0.6325 - val_loss: 2.7664 - val_accuracy: 0.2730 - val_categorical_crossentropy: 2.7664\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6205 - accuracy: 0.7715 - categorical_crossentropy: 0.6205 - val_loss: 2.7816 - val_accuracy: 0.2750 - val_categorical_crossentropy: 2.7816\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6375 - accuracy: 0.7735 - categorical_crossentropy: 0.6375 - val_loss: 2.7875 - val_accuracy: 0.2750 - val_categorical_crossentropy: 2.7875\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6444 - accuracy: 0.7586 - categorical_crossentropy: 0.6444 - val_loss: 2.7997 - val_accuracy: 0.2720 - val_categorical_crossentropy: 2.7997\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.6146 - accuracy: 0.7724 - categorical_crossentropy: 0.6146 - val_loss: 2.8179 - val_accuracy: 0.2720 - val_categorical_crossentropy: 2.8179\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6197 - accuracy: 0.7737 - categorical_crossentropy: 0.6197 - val_loss: 2.8363 - val_accuracy: 0.2790 - val_categorical_crossentropy: 2.8363\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6143 - accuracy: 0.7721 - categorical_crossentropy: 0.6143 - val_loss: 2.8472 - val_accuracy: 0.2650 - val_categorical_crossentropy: 2.8472\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.6151 - accuracy: 0.7688 - categorical_crossentropy: 0.6151 - val_loss: 2.8508 - val_accuracy: 0.2770 - val_categorical_crossentropy: 2.8508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3VeD5eg5KIe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "ecc37a7c-ee66-4ccf-e6ec-a71ca688c159"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 64\n",
        "vocab_in_size = 100\n",
        "len_input_train = 4\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Input((100, 4)))\n",
        "#model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=len_input_train))\n",
        "model_lstm.add(LSTM(units))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.summary()\n",
        "\n",
        "history_lstm = model_lstm.fit(trainX, trainY, \n",
        "                              epochs=10, batch_size=BATCH_SIZE, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 64)                17664     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 17,729\n",
            "Trainable params: 17,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1203/7000 [====>.........................] - ETA: 1:36 - loss: 5.8663e-08 - accuracy: 0.5021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6e796160e392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c5q7ZrEEJ1h"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import  Conv1D, GRU, LSTM, TimeDistributed, Concatenate, Softmax, Activation, Flatten, Dense, Input, Bidirectional, Attention\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "import os\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"  # for tf 2.0\n",
        "\n",
        "main_input = Input((100, 4))\n",
        "cur_p1 = Conv1D(filters=16, kernel_size=3, padding='SAME')(main_input)\n",
        "cur_p2 = Conv1D(filters=16, kernel_size=3, padding='SAME')(main_input)\n",
        "cur1 = Attention()([cur_p1, main_input, cur_p2])\n",
        "\n",
        "cur = Concatenate()([cur1, main_input])\n",
        "cur = Bidirectional(GRU(4, return_sequences=True))(cur)\n",
        "\n",
        "d = Dense(4, activation='relu') (cur)\n",
        "d = TimeDistributed(Dense(1, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1))) (d)\n",
        "\n",
        "d = Flatten()(d)\n",
        "\n",
        "main_output = d\n",
        "model = Model(main_input, main_output)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='mse', metrics=['mse', 'accuracy'])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFBPmXEm8D1G",
        "outputId": "73d28372-f610-4064-cc03-b85d536b260d"
      },
      "source": [
        "len(trainX[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEL5zPTtE7Fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "bafd2f1d-4cd7-482f-d5bf-357827db6321"
      },
      "source": [
        "history = model.fit(trainX, trainY, \n",
        "                              epochs=10, batch_size=BATCH_SIZE, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2740 - mse: 0.2539 - accuracy: 0.0000e+00 - val_loss: 0.2557 - val_mse: 0.2502 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 171s 24ms/step - loss: 0.2560 - mse: 0.2520 - accuracy: 0.0000e+00 - val_loss: 0.2542 - val_mse: 0.2514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 175s 25ms/step - loss: 0.2540 - mse: 0.2514 - accuracy: 0.0000e+00 - val_loss: 0.2563 - val_mse: 0.2537 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2529 - mse: 0.2508 - accuracy: 0.0000e+00 - val_loss: 0.2550 - val_mse: 0.2528 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "7000/7000 [==============================] - 172s 25ms/step - loss: 0.2528 - mse: 0.2510 - accuracy: 0.0000e+00 - val_loss: 0.2555 - val_mse: 0.2536 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "7000/7000 [==============================] - 170s 24ms/step - loss: 0.2529 - mse: 0.2514 - accuracy: 0.0000e+00 - val_loss: 0.2551 - val_mse: 0.2534 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "7000/7000 [==============================] - 171s 24ms/step - loss: 0.2525 - mse: 0.2511 - accuracy: 0.0000e+00 - val_loss: 0.2534 - val_mse: 0.2522 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "5230/7000 [=====================>........] - ETA: 41s - loss: 0.2526 - mse: 0.2512 - accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-591bce46bbc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJI6ze-T-NR5"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz7xoJpw-Wld"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e1ZxgOO-ZMN"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4o9nmJ-bTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "b99b2420-0d09-4ced-cfa2-e1ac45a28e5a"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = Input(shape=(100,4))\n",
        "embedding_layer = TokenAndPositionEmbedding(100, 4, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a67acc1f7b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtransformer_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-8-0ee9fb568205>:14 call  *\n        attn_output = self.att(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:926 __call__  **\n        input_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1137 _functional_construction_call\n        '(layer: ' + self.name + ').')\n\n    ValueError: A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: multi_head_self_attention_2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_OhRdVMFneJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "bab3a2b7-bdd0-4fdb-ec3f-6932a3b2948d"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e3bbca2ec601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n\u001b[0m\u001b[1;32m      3\u001b[0m     (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLggnVbz-QBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "feec7351-cd2f-450e-a766-e7d8e86bbf35"
      },
      "source": [
        "d_model = 512\n",
        "dff=2048\n",
        "maximum_position_encoding = 10000\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "\n",
        "scaling_factor = tf.keras.backend.constant(np.sqrt(d_model), shape = (1,1,1))\n",
        "\n",
        "\n",
        "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "# Encoder ##################################\n",
        "input = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "x = tf.keras.layers.Embedding(input_vocab_size, d_model)(input) #, mask_zero=True\n",
        "\n",
        "## positional encoding\n",
        "x = tf.keras.layers.Multiply()([x,scaling_factor])\n",
        "pos = positional_encoding(maximum_position_encoding, d_model)\n",
        "x = tf.keras.layers.Add()([x, pos[: , :tf.shape(x)[1], :]] )\n",
        "\n",
        "## self-attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(x)\n",
        "key = tf.keras.layers.Dense(d_model)(x)\n",
        "attention = tf.keras.layers.Attention()([query, value, key])                   # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## Feed Forward\n",
        "dense = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "dense = tf.keras.layers.Dense(d_model)(dense)\n",
        "x = tf.keras.layers.Add()([x , dense])                                          # residual connection\n",
        "encoder = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "# Decoder ##################################\n",
        "target = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "x = tf.keras.layers.Embedding(target_vocab_size, d_model )(target) # , mask_zero=True\n",
        "\n",
        "## positional encoding\n",
        "x = tf.keras.layers.Multiply()([x,scaling_factor])\n",
        "pos = positional_encoding(maximum_position_encoding, d_model)\n",
        "x = tf.keras.layers.Add()([x, pos[: , :tf.shape(x)[1], :] ])\n",
        "\n",
        "## self-attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(x)\n",
        "key = tf.keras.layers.Dense(d_model)(x)\n",
        "attention = tf.keras.layers.Attention(causal = True)([query, value, key])       # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])                                      # residual connection\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## encoder-decoder attention\n",
        "query = tf.keras.layers.Dense(d_model)(x)\n",
        "value = tf.keras.layers.Dense(d_model)(encoder)\n",
        "key = tf.keras.layers.Dense(d_model)(encoder)\n",
        "attention = tf.keras.layers.Attention()([query, value, key])                    # , mask=[query._keras_mask, value._keras_mask]\n",
        "attention = tf.keras.layers.Dense(d_model)(attention)\n",
        "\n",
        "x = tf.keras.layers.Add()([x , attention])                                      # residual connection\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "## Feed Forward\n",
        "dense = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "dense = tf.keras.layers.Dense(d_model)(dense)\n",
        "x = tf.keras.layers.Add()([x , dense])                                          # residual connection\n",
        "decoder = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "######################################################\n",
        "\n",
        "x = tf.keras.layers.Dense(target_vocab_size)(decoder)\n",
        "\n",
        "base_model = tf.keras.models.Model(inputs=[input,target], outputs=x)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-22a3b85dd0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmaximum_position_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minput_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_pt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer_pt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYvKr6ocGIm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c02b97-5d1d-483b-8941-cb3541c479c4"
      },
      "source": [
        "!pip install -U transformers-keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers-keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/d0/6831dd9a37863fde38772fbdd9b06287f89d1213c68d5d8a1c0f21f365c8/transformers_keras-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jieba in /usr/local/lib/python3.6/dist-packages (from transformers-keras) (0.42.1)\n",
            "Installing collected packages: transformers-keras\n",
            "Successfully installed transformers-keras-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s7eCCiMG6AA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "4f258001-35e0-48aa-d310-db19cccab737"
      },
      "source": [
        "df = pd.DataFrame({'x': trainX.flatten(), 'y': trainY.flatten()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9bb82c3ae101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2juk1YGTGX"
      },
      "source": [
        "from transformers_keras import BertTFRecordDatasetBuilder\n",
        "\n",
        "builder = BertTFRecordDatasetBuilder(max_sequence_length=128, record_option='GZIP')\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='acc')\n",
        "model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
        "model(model.dummy_inputs())\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_dataset, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP0uuUxFH8VT"
      },
      "source": [
        "class Transformer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 src_vocab_size=-1,\n",
        "                 tgt_vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "        assert src_vocab_size > 0, \"src_vocab_size must greater than 0.\"\n",
        "        assert tgt_vocab_size > 0, \"tgt_vocab_size must greater than 0.\"\n",
        "        self.src_vocab_size = src_vocab_size\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_encoder_layers = num_encoder_layers\n",
        "        self.num_decoder_layers = num_decoder_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.encoder = TransformerEncoder(\n",
        "            src_vocab_size, max_positions, hidden_size,\n",
        "            num_layers=num_encoder_layers, dropout_rate=dropout_rate, epsilon=epsilon)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            tgt_vocab_size, max_positions, hidden_size,\n",
        "            num_layers=num_encoder_layers, dropout_rate=dropout_rate, epsilon=epsilon)\n",
        "        self.dense = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x_ids, y_ids = inputs\n",
        "\n",
        "        def _create_padding_mask(x):\n",
        "            mask = tf.cast(tf.equal(0, x), dtype=tf.float32)\n",
        "            mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
        "            return mask\n",
        "\n",
        "        def _create_look_ahead_mask(size):\n",
        "            mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "            return mask\n",
        "\n",
        "        def _create_masks(x, y):\n",
        "            _enc_padding_mask = _create_padding_mask(x)\n",
        "            _dec_padding_mask = _create_padding_mask(x)\n",
        "            _look_ahead_mask = _create_look_ahead_mask(tf.shape(y)[1])\n",
        "            _target_padding_mask = _create_padding_mask(y)\n",
        "            combined = tf.maximum(_look_ahead_mask, _target_padding_mask)\n",
        "            return _enc_padding_mask, combined, _dec_padding_mask\n",
        "\n",
        "        enc_padding_mask, dec_look_ahead_mask, dec_padding_mask = _create_masks(x_ids, y_ids)\n",
        "\n",
        "        enc_outputs, enc_attns = self.encoder(inputs=(x_ids, enc_padding_mask))\n",
        "\n",
        "        dec_outputs, dec_attns_0, dec_attns_1 = self.decoder(\n",
        "            inputs=(y_ids, enc_outputs, dec_look_ahead_mask, dec_padding_mask))\n",
        "\n",
        "        logits = self.dense(dec_outputs)\n",
        "        return logits, enc_attns, dec_attns_0, dec_attns_1\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"src_vocab_size\": self.src_vocab_size,\n",
        "            \"tgt_vocab_size\": self.tgt_vocab_size,\n",
        "            \"max_positions\": self.max_positions,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"num_encoder_layers\": self.num_encoder_layers,\n",
        "            \"num_decoder_layers\": self.num_decoder_layers,\n",
        "            \"num_attention_heads\": self.num_attention_heads,\n",
        "            \"ffn_size\": self.ffn_size,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"epsilon\": self.epsilon,\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kA5uWOAIX5v"
      },
      "source": [
        "\n",
        "class TransformerEmbedding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, vocab_size=1, max_positions=512, embedding_size=512, dropout_rate=0.2, **kwargs):\n",
        "        super(TransformerEmbedding, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.embedding_size = embedding_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.token_embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_size)\n",
        "        self.positional_encoding = PositionalEncoding(self.max_positions, self.embedding_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids = inputs\n",
        "        token_embeddings = self.token_embedding(token_ids)\n",
        "        position_embeddings = self.positional_encoding(token_ids)\n",
        "        embedding = token_embeddings + position_embeddings\n",
        "        embedding = self.dropout(embedding, training=training)\n",
        "        return embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        conf = {\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'embedding_size': self.embedding_size,\n",
        "            'dropout_rate': self.dropout_rate\n",
        "        }\n",
        "        p = super(TransformerEmbedding, self).get_config()\n",
        "        return dict(list(p.items()) + list(conf.items()))\n",
        "\n",
        "\n",
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.embedding = TransformerEmbedding(vocab_size, max_positions, hidden_size, dropout_rate)\n",
        "        self.encoders = [\n",
        "            EncoderLayer(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                ffn_size=ffn_size,\n",
        "                dropout_rate=dropout_rate,\n",
        "                epsilon=epsilon,\n",
        "                name='EncoderLayer{}'.format(i)\n",
        "            ) for i in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids, mask = inputs\n",
        "        embeddings = self.embedding(inputs=token_ids)\n",
        "\n",
        "        attn_weights = []\n",
        "        outputs = embeddings\n",
        "        for i in range(self.num_layers):\n",
        "            encoder = self.encoders[i]\n",
        "            outputs, weights = encoder(inputs=(outputs, outputs, outputs, mask))\n",
        "            attn_weights.append(weights)\n",
        "\n",
        "        return outputs, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_layers': self.num_layers,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        p = super().get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size=-1,\n",
        "                 max_positions=512,\n",
        "                 hidden_size=512,\n",
        "                 num_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 ffn_size=2048,\n",
        "                 dropout_rate=0.2,\n",
        "                 epsilon=1e-6,\n",
        "                 **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        assert vocab_size > 0, \"vocab_size must greater than 0.\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_positions = max_positions\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.embedding = TransformerEmbedding(vocab_size, max_positions, hidden_size, dropout_rate)\n",
        "        self.decoders = [\n",
        "            DecoderLayer(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                ffn_size=ffn_size,\n",
        "                dropout_rate=dropout_rate,\n",
        "                epsilon=epsilon,\n",
        "                name='DecoderLayer{}'.format(i)\n",
        "            ) for i in range(self.num_layers)\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids, enc_outputs, look_ahead_mask, padding_mask = inputs\n",
        "        embeddings = self.embedding(token_ids)\n",
        "\n",
        "        self_attn_weights, context_attn_weights = [], []\n",
        "        outputs = embeddings\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            decoder = self.decoders[i]\n",
        "            outputs, self_attn, context_attn = decoder(inputs=(outputs, enc_outputs, look_ahead_mask, padding_mask))\n",
        "            self_attn_weights.append(self_attn)\n",
        "            context_attn_weights.append(context_attn)\n",
        "\n",
        "        return outputs, self_attn_weights, context_attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_layers': self.num_layers,\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'max_positions': self.max_positions,\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        p = super(TransformerDecoder, self).get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHhwHOQkIhyw"
      },
      "source": [
        "class TransformerLearningRate(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \"\"\"Learning rate schedule for Transformer.\"\"\"\n",
        "\n",
        "    def __init__(self, depth, warmup_steps=4000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            depth: Python integer, the model's hidden size\n",
        "            warmup_steps: Python integer, steps to warmup learning rate\n",
        "        \"\"\"\n",
        "        self.depth = depth\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(tf.cast(self.depth, tf.float32)) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'depth': self.depth,\n",
        "            'warmup_steps': self.warmup_steps\n",
        "        }\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZjRzg4bJAUI"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, max_positions=512, embedding_size=512, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.max_positions = max_positions\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        def _initializer(shape, dtype=tf.float32):\n",
        "            pos = np.arange(self.max_positions)[:, tf.newaxis]\n",
        "            d = np.arange(self.embedding_size)[tf.newaxis, :]\n",
        "            rads = 1 / np.power(10000, (2 * (d // 2)) / np.float32(self.embedding_size))\n",
        "            rads = pos * rads\n",
        "\n",
        "            rads[:, 0::2] = np.sin(rads[:, 0::2])\n",
        "            rads[:, 1::2] = np.cos(rads[:, 1::2])\n",
        "\n",
        "            rads = tf.cast(rads, dtype=dtype)\n",
        "            rads = tf.reshape(rads, shape=shape)\n",
        "            return rads\n",
        "\n",
        "        self.position_embedding = self.add_weight(\n",
        "            name='position_embedding',\n",
        "            shape=(self.max_positions, self.embedding_size),\n",
        "            dtype=tf.float32,\n",
        "            initializer=_initializer,\n",
        "            trainable=False)\n",
        "\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        token_ids = inputs\n",
        "        pos_embedding = self.position_embedding[tf.newaxis, :]\n",
        "        embedding = pos_embedding[:, :tf.shape(token_ids)[1], :]\n",
        "        return embedding\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'max_positions': self.max_positions,\n",
        "            'embedding_size': self.embedding_size\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2-BebvSJNHM"
      },
      "source": [
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, ffn_size=2048, dropout_rate=0.2, epsilon=1e-6, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(self.hidden_size, self.ffn_size)\n",
        "        self.ffn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.ffn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        attn, attn_weights = self.attention(inputs=(query, key, value, mask))\n",
        "        attn = self.attn_dropout(attn, training=training)\n",
        "        attn = self.attn_layer_norm(query + attn)\n",
        "\n",
        "        ffn = self.ffn(attn)\n",
        "        ffn = self.ffn_dropout(ffn, training=training)\n",
        "        ffn = self.ffn_layer_norm(ffn + attn)\n",
        "\n",
        "        return ffn, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, ffn_size=2048, dropout_rate=0.2, epsilon=1e-6, **kwargs):\n",
        "        super(DecoderLayer, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.ffn_size = ffn_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.self_attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.self_attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.self_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.context_attention = MultiHeadAttention(self.hidden_size, self.num_attention_heads)\n",
        "        self.context_attn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.context_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "        self.ffn = PointWiseFeedForwardNetwork(self.hidden_size, self.ffn_size)\n",
        "        self.ffn_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.ffn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=self.epsilon)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x, enc_outputs, look_ahead_mask, padding_mask = inputs\n",
        "\n",
        "        attn1, attn1_weights = self.self_attention(inputs=(x, x, x, look_ahead_mask))\n",
        "        attn1 = self.self_attn_dropout(attn1, training=training)\n",
        "        output1 = self.self_attn_layer_norm(attn1 + x)\n",
        "\n",
        "        attn2, attn2_weights = self.context_attention(inputs=(output1, enc_outputs, enc_outputs, padding_mask))\n",
        "        attn2 = self.context_attn_dropout(attn2, training=training)\n",
        "        output2 = self.context_attn_layer_norm(attn2 + output1)\n",
        "\n",
        "        ffn = self.ffn(output2)\n",
        "        ffn = self.ffn_dropout(ffn, training=training)\n",
        "        ffn = self.ffn_layer_norm(ffn + attn2)\n",
        "\n",
        "        return ffn, attn1_weights, attn2_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads,\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "            'epsilon': self.epsilon\n",
        "        }\n",
        "        base = super(DecoderLayer, self).get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMTQedF8JhhI"
      },
      "source": [
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, num_attention_heads=8, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        assert self.hidden_size % self.num_attention_heads == 0\n",
        "\n",
        "        self.query_weight = tf.keras.layers.Dense(self.hidden_size, name='query')\n",
        "        self.key_weight = tf.keras.layers.Dense(self.hidden_size, name='key')\n",
        "        self.value_weight = tf.keras.layers.Dense(self.hidden_size, name='value')\n",
        "\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(self.hidden_size, name='dense')\n",
        "\n",
        "    def _split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_attention_heads, self.hidden_size // self.num_attention_heads))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        query = self._split_heads(self.query_weight(query), batch_size)\n",
        "        key = self._split_heads(self.key_weight(key), batch_size)\n",
        "        value = self._split_heads(self.value_weight(value), batch_size)\n",
        "\n",
        "        context, attn_weights = self.attention(inputs=(query, key, value, mask))\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])\n",
        "        context = tf.reshape(context, [batch_size, -1, self.hidden_size])\n",
        "        output = self.dense(context)\n",
        "        return output, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'hidden_size': self.hidden_size,\n",
        "            'num_attention_heads': self.num_attention_heads\n",
        "        }\n",
        "        base = super().get_config()\n",
        "        return dict(list(base.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Csj6knJpwd"
      },
      "source": [
        "class ScaledDotProductAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        query, key, value, mask = inputs\n",
        "        query = tf.cast(query, dtype=self.dtype)\n",
        "        key = tf.cast(key, dtype=self.dtype)\n",
        "        value = tf.cast(value, dtype=self.dtype)\n",
        "\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dk = tf.cast(tf.shape(query)[-1], tf.float32)\n",
        "        score = score / tf.math.sqrt(dk)\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=self.dtype)\n",
        "            score += mask * -10000.0\n",
        "        attn_weights = tf.nn.softmax(score, axis=-1)\n",
        "        context = tf.matmul(attn_weights, value)\n",
        "        return context, attn_weights\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "\n",
        "class PointWiseFeedForwardNetwork(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, hidden_size=512, ffn_size=2048, **kwargs):\n",
        "        super(PointWiseFeedForwardNetwork, self).__init__(**kwargs)\n",
        "        self.ffn_size = ffn_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dense1 = tf.keras.layers.Dense(self.ffn_size, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(self.hidden_size)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        outputs = self.dense2(self.dense1(inputs))\n",
        "        return outputs\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'ffn_size': self.ffn_size,\n",
        "            'hidden_size': self.hidden_size,\n",
        "        }\n",
        "        p = super(PointWiseFeedForwardNetwork, self).get_config()\n",
        "        return dict(list(p.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBHA83CH-BH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "05552164-58c8-4203-e925-06d5bb200339"
      },
      "source": [
        "x = tf.keras.layers.Input((None, 100, 4), dtype=tf.int32, name='x')\n",
        "y = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='y')\n",
        "model = Transformer(src_vocab_size=4,\n",
        "                 tgt_vocab_size=4)\n",
        "inputs=Input(shape=(100,4))\n",
        "logits, _, _, _ = model(inputs=inputs)\n",
        "probs = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.nn.softmax(x), name='probs')(logits)\n",
        "\n",
        "model = tf.keras.Model(inputs=[x, y], outputs=[probs])\n",
        "\n",
        "lr = 0.1 #TransformerLearningRate(config.get('hidden_size', 512))\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(name='loss', from_logits=False),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='acc')],\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    <ipython-input-29-c8c5ccfc8e75>:37 call  *\n        x_ids, y_ids = inputs\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:479 _disallow_in_graph_mode\n        \" this function with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-ccde5946f3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                  tgt_vocab_size=4)\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m probs = tf.keras.layers.Lambda(\n\u001b[1;32m      8\u001b[0m     lambda x: tf.nn.softmax(x), name='probs')(logits)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                             \u001b[0;34m'dynamic. Pass `dynamic=True` to the class '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                             \u001b[0;34m'constructor.\\nEncountered error:\\n\"\"\"\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                             '\\n\"\"\"')\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m           \u001b[0;31m# We will use static shape inference to return symbolic tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\nEncountered error:\n\"\"\"\nin user code:\n\n    <ipython-input-29-c8c5ccfc8e75>:37 call  *\n        x_ids, y_ids = inputs\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:503 __iter__\n        self._disallow_iteration()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:499 _disallow_iteration\n        self._disallow_in_graph_mode(\"iterating over `tf.Tensor`\")\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:479 _disallow_in_graph_mode\n        \" this function with @tf.function.\".format(task))\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\n\n\"\"\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ125GE0KTYD"
      },
      "source": [
        "epochs=10,\n",
        "ckpt_steps=2000,\n",
        "export_steps=5000,\n",
        "callbacks=None,\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuTWJ852LCok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "aa91de12-63f4-4395-f144-ee68fe67a4e2"
      },
      "source": [
        "history = model.fit(trainX, trainY, \n",
        "                              epochs=10, \n",
        "                              # verbose=2,\n",
        "                              validation_data=(valX, valY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"x_10:0\", shape=(None, 100), dtype=int32), but it was called on an input with incompatible shape (None, 100, 4).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-21a093d94e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0;31m# verbose=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               validation_data=(valX, valY))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"probs/Softmax_2:0\", shape=(None, 4, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN_CQOS9KltM"
      },
      "source": [
        "        history = self.model.fit(\n",
        "            train_dataset,\n",
        "            validation_data=valid_dataset,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}